{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import haversine as hs\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import norm\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# y_true, y_pred\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# https://stackoverflow.com/questions/70452465/how-to-load-in-graph-from-networkx-into-pytorch-geometric-and-set-node-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected features and read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['accommodates', 'latitude', 'longitude',\n",
    "            'number_of_reviews', 'calculated_host_listings_count', 'bedrooms',\n",
    "           'beds', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "           'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df = pd.read_csv('santorini_listings.csv')\n",
    "listings_df['price_log'] = np.log(listings_df['price'])\n",
    "\n",
    "listings_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listings_df = listings_df[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEJCAYAAAC61nFHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5fUlEQVR4nO3deXxdZZ348c+92fc0yU2TNE3btPTbjTZdoYVWtBUUUQRZFLSCisOgjtuo4w+Y0XFwFPj9UGdAZ2BmYMSCDiOblEWg0kIpLXTfvt3TZmvT7Pt27++Pe1NCmiY3t7lb8n2/Xnn1nnOec873nib3e8/zPOd5HB6PB2OMMWa4nOEOwBhjTHSyBGKMMSYglkCMMcYExBKIMcaYgFgCMcYYE5DYcAcQIgnAYqAS6AlzLMYYEy1igHxgC9DRf+NYSSCLgQ3hDsIYY6LUcuDN/iuDmkBE5CbgLiAeeEBVH+y3/Wrgx4ADOArcqqp1IlIEPA7kAgrcrKrNIpIJ/A4oBqqBG1S1yo9QKgHq6lpwu6PruZfs7FRqaprDHUbEsetyNrsmA7PrcjZ/r4nT6WDcuBTwfYb2F7QEIiITgHuAhXhvfTaKyDpV3evbng78GlisquUi8o/Aj4BvAg8BD6nqkyJyN3A38APgn4ANqvoJEfkC8EvgRj/C6QFwuz1Rl0CAqIw5FOy6nM2uycDsupxtmNdkwKr/YDairwJeV9VaVW0BngKu67M9DrhDVct9yzuBIhGJA1b4ygM8Clzve/0JvHcgAE8AH/eVN8YYE2LBTCAFfPC2pxIo7F1Q1RpVfQZARJKAvwOeAXKARlXtHmC/M8f0bW8EXEF7B8YYY84pmG0gjgHWufuvEJEMvIljh6o+JiIFg+zn1zHPJTs71d+iEcXlSgt3CBHJrsvZ7JoMzK7L2UbimgQzgZTjbbnvlQ9U9C0gIvnAy8DrwLd9q6uBdBGJUdWefvuVA3lAmYjEAulAjb8B1dQ0R11dqMuVRnV1U7jDiDh2Xc5m12Rgdl3O5u81cTodg37xDmYV1qvAShFxiUgy8Bngpd6NIhID/An4g6p+S1U9AKrahbfLbW/j+GrgRd/rtb5lfNs3+MobY4wJsaDdgfh6Vt0JrMPbjfcRVd0sImuBvwcmAvOBGBHpbVx/V1W/AtwBPCYidwHHgc/5tt8NPCoie4B64OZgxW+MMWZwjjEyH8hk4KhVYY0edl3OZtdkYHZdzhZAFdYU4Fj/7WPlSXQzRmVkJhMfFxOy83V29dBQ3xqy8xkTTpZAzKgWHxfDw3/cEbLz3XbtvJCdy5hws9F4jTHGBMQSiDHGmIBYAjHGGBMQSyDGGGMCYgnEGGNMQCyBGGOMCYglEGOMMQGxBGKMMSYglkCMMcYExJ5ENzbchzEmIJZAjA33YYwJiFVhGWOMCYglEGOMMQGxBGKMMSYglkCMMcYExBKIMcaYgAS1F5aI3ATchXdO9AdU9cFzlHsMWKeqj4pILvBKn80ZgEtVU0VkBfA0cMK3bZuq3hq8d2CMMeZcgpZARGQCcA+wEOgANorIOlXd26dMAfBvwEpgHYCqngJKfNudwGvAnb5dFgP3q+o/BytuY4wx/gnmHcgq4HVVrQUQkaeA64B/7FPmZuBZoOYcx7gVaFXVNb7lxUCuiNyA9y7ka6p64hz7GmOMCaJgJpACoLLPciWwpG8BVb0PQEQu7b+ziMTgrf76VJ/V9cATqvqsiNwOPAlc4m9A2dmp/haNKC5XWtDPkZKSEPRz9DUS78nfY0Tje4vGc0cyuy5nG4lrEswE4hhgnXsY+38MOKCqu3pXqOrtfV7/RkR+JiIZqtrgzwFrappxuz3DCCH8XK40qqubgn6OlpaOoJ6jv/N9T/5el2h8b4EKxe9KNLLrcjZ/r4nT6Rj0i3cwe2GVA3l9lvOBimHs/2m8dxiAtz1ERO703Zn01RVwhMYYYwIWzATyKrBSRFwikgx8BnhpGPsvBTb0LqiqG7jGdxxEZDXwjqraqHyjhNvtob2zm+a2LhqaO2ht78Ltia47RmPGkqBVYalquYjcibd3VTzwiKpuFpG1wN+r6rtDHKIYKOu37ovAwyLyD8ApYPVIx21C52RdK9sPnuZgWQMnTjVR29hBT78qRocDUhLjyEiNx5WRRE5GIjmZSUwtGkdyrANXZhKxMfY4kzHhENTnQHy9p9b0W3flAOVuGWBd8gDr9gDLRjBEE2Iej4eNOyv4n9cOcKjM23SVOy6JyXnpLJmZRHJiLLExTmKdDrq63TS3d9PS1kVdUwenG9rYd7yOjs6eM8eLcToYn5VMfnYy+dkpFPj+zc8O7RD1xoxFNpy7CZn65g52Hanl+Y2luDITueHD01gkLnIyk/w+hsfjobmtiy4c7Dt8moqaFipPt1J2qpmtB6rprfFyOhwU5KQwc0oWVaebyUxNICMlHqdzoL4dxphAWAIxQefxeDhU3sD+4/XEx8bwzRvnc+GkzIA+zB0OB2nJ8bhcaWQlx31gW1d3Dydr26ioaaGsupljVU28s6eKxpZOwHu3kpORiCszifFZSaQkxg10CmOMnyyBmKDqcbvZdvA0FadbKchOZu60bFYtKQpKt8q42BgKc1MpzE1lyczxAOTkpPKrJ7ZS39zB6YZ2quvbOFnXxu6jkJkazwRXCoU5qSTEW3WXMcNlCcQETXePm837TnG6oZ2Zk8YxbUI6Dkdoq5AcDgfJibEkJ8ZSkJMCQEt7F5WnWyk/3cKeo3XsO1ZHoSuV4gnppCfHhzQ+Y6KZJRATFD1uD1v2e5PH/AtymJgbOaMApCTGMa0wg2mFGTS1dnKksomyU80cP9VMXlYSsyZlkZps1VvGDMX6P5oR5/F42Hm4hur6dkqmZUdU8ugvLTmeeVOzWbWoEJmYyemGdtZtL2fXkRo6unqGPoAxY5jdgZgRd6SikROnmpk+MYOi8dExBlFCXAxSlMnkvDT2n6jnaGUT5dUtzJ2WTUF2SrjDMyYi2R2IGVF1TR3sLa0jLysZmZgZ7nCGLSE+hnlTs7mspICkhFje3V/Neweq6ey2uxFj+rMEYkZMV7eb97SaxPgY5l+QHfIG85GUnhLP8rn5yMRMKk638Ma2CuqaQjsoozGRzhKIGTF7S+to7ehm4XQXcbHR3y3W6XQgRZksn5sPDnhrVyXHT9qorsb0sgRiRsTphnZKq5ooLkgnKz0x3OGMqMzUBD40r4Cs9ES2H6ph5+EaG+TRGCyBmBHgdnvYefg0yQmxzCjKDHc4QREfF8PS2eOZOiGdY1VNbNl3iu6e4UxvY8zoYwnEnLejlY00t3UzpzhrVI+M63A4mD05i7nFWZysa2Pj7irr6mvGtNH7125CoqOrBz1RT25mEuPH+T8oYjSbnJ/O4hm5NLZ28ebOSto6usMdkjFhYQnEnJcDJ+rp6fEwe8q4qO51NVz52cksmz2ejq4e3tpVRWu7TYxpxh5LICZgre1dlFY1MXF8KmljcAyprPREls7Oo6vbzVu7q2hpsyRixhZLICZgesI7IVQ0PjA4UsalJbBszni6ezy8tbuK8urmcIdkTMgEdSgTEbkJuAvvlLYPqOqD5yj3GLBOVR/1La8Gfg6c9BV5QVXvFJEi4HEgF1DgZlW1v9gwaG3vouxUM1Py00lKGNsj4mSkJrBsTh5v76nihw++yXdvLDkz8q8xo1nQ7kBEZAJwD3ApMA/4qojM6lemQESeB67vt/ti4DuqWuL7udO3/iHgIVWdAbwL3B2s+M3gDlc0ggOmTkgPdygRISMlnkvm5AFw7xPbqKxpCXNExgRfMKuwVgGvq2qtqrYATwHX9StzM/As8Id+6xcDq0Vkh4g8LiLjRCQOWOE7DsCjnJ14TAh0dPZQerKZia7UMX/30Vdacjz3/PUlANy7xpKIGf2CmUAKgMo+y5VAYd8Cqnqfqj4ywL6VwI+AEuAE8K9ADtCoqt19yhQOsK8JsqOVjbjdHrv7GMDE8Wl873Pz8Xg83PvENqpqW8MdkjFBE8yvjwP16fTr0V1Vvab3tYjcCxwBvhfo8XplZ0fuvBSDcbmCPyR6SkqCX+W6ut0crWqiMDeVvPOIayTek7/H8Pe9jZSSmXn89GuXcuev3+L+J7fzz3dcQoErNL97ofhdiUZ2Xc42EtckmAmkHFjeZzkfqBhqJxHJAL6kqg/4VjmALqAaSBeRGFXt8fd4fdXUNON2R9cYRi5XWlDmD+9/jpYW/0aaPVTeQFe3myl5/u8zkPN9T/5el+G8t5FSXd1EcoyD795Ywr1rtvF3D77J92+az/hxyUE9byh+V6KRXZez+XtNnE7HoF+8g1mF9SqwUkRcIpIMfAZ4yY/9moHvi8hFvuWvA0+rahewAbjRt3418OIIx2wG4fZ4OFLRSE5GIuPSQvutPhoVulL53ufm09Xt5t412zhV3xbukIwZUUFLIKpaDtwJrAO2A2tUdbOIrBWRRYPs1wPcAPxaRPYBC4Hv+zbfgbc31168dzd3BSt+c7aq2lbaO3sozre2D39NzE3lbz9bQmdXD/et2Uq1JREzigS1C42qrgHW9Ft35QDlbum3vAFYMEC5UuCyEQ3S+O1YZRNJCTGMzxobY16NlCJfw/p9T2zj3jXb+MFN88nJtGtoop/1wTR+aWrt5HRDOzOKMs97zKueHndIG9EjQdH4NP72s/O5/8lt3PvENr5/03xyMiyJmOhmCcT4pbSqCYfD+0F4vmJinDz8xx3ndYyUlAS/Gsdvu3beeZ1nJE3KS+O7ny3h/ie28/PfbeU7N5aQn21PrJvoZWNhmSF197g5fqqZguwUEuOjf6racJqcl873b/I2rP/z41s5VtUY7pCMCZglEDOk8uoWuns8TM6PniqjSFY0Po0ffn4hifEx/HzNNvaV1oU7JGMCYgnEDMrj8XCsqon05DiyrOvuiBmflcwPP7+QnIxEHvjDdt7TU+EOyZhhswRiBtXQ0klDSyeT8tLG1IRRoTAuLYG/u3kBk/PSeeiZ3fx5ywk8nuh60NWMbZZAzKBOnGrG6YAJLmvsDYaUxDi++9kSSqbl8MRrB3n0xf10dQ9rhB5jwsYSiDmnHreHsuoW8rKTiY+1xvNgSYiL4WvXXshVyyazYWcl9z25jcaWznCHZcyQLIGYczpZ20pXt5uiXGs8Dzanw8G1K4q5/erZHK9q4iePbeH4SRu/yUQ2SyDmnI6faiYxPgZXZmK4Qxkzlswcz999fgFuD/z0t++xfkeFtYuYiGUJxAyoraObU3VtTMxNtcbzEJucl87f37KYqRMyePTF/Tzyp720d3YPvaMxIWZPopsBlVV7p5qfmBudc6hEu4yUeL57Ywl/evsYz755lKOVTdzx6TkU9vv/yMhMJj7u/fapYA7v0tnVQ0O9TZBl3mcJxJzF4/Fw/GQzWekJpCbFhTucMcvpdPCpS6ZwQWEm//7cHn7y3+9y06oLWDGv4MxdYXxczJlhYfwd3iVQkTQsjIkMVoVlzlLf3ElLe7fdfUSImZPG8aMvLWF6YQaPvaT8+/N7aeuwKi0TfpZAzFnKq73PfhRkB3cGPeO/jJR4vn1jCdeuKGbzvpP8+NEtlFZZLy0TXpZAzAd4PB7KT7eQOy6ZOHv2I6I4HQ6uWjaZH9y0gK5uN/f89l1eeOuo9dIyYWNtIOYDqhva6ehyU2hPngdkpOY6GYzLlcac6bn84slt/OaPO8nPTqZkWnZQz2nMQCyBmA8or24hNsZhsw4GaCTmOvFX/rhEbr1qNo++sIf1Ozq5bOFE7J7RhFJQE4iI3IR33vJ44AFVffAc5R4D1qnqo77lS4BfAHFADfAlVS0VkRXA08AJ367bVPXWYL6HsaSnx01lTQv52SnEOK12M9I5HA6u/fA0DhyrYcv+U7zyTimLxIXLpss1IRK0TwkRmQDcA1wKzAO+KiKz+pUpEJHngev77f474MuqWuJ7/Svf+sXA/apa4vux5DGCTta10d3jseqrKJOdkcjyefkkJ8ayac9JjlnjugkRvxKIiHxSRIb7OPIq4HVVrVXVFuAp4Lp+ZW4GngX+0OdcCcBdqrrTt2onUOR7vRj4qIhsE5HnRGTiMGMygyirbiEhLoacDBu6JNqkJMbx0SWTcI1LYufhGg6WNYQ7JDMG+HsH8g3gqIjcJSJ5fu5TAFT2Wa4ECvsWUNX7VPWRfus6VPVxABFxAj8CnvFtrgd+qarzgbXAk37GYobQ2d3DqbpWJuSk2NAlUSou1smSGbkU5CSzr7SOfaV11kPLBJVfbSCqermITAVuAzaLyCbgN6r6+iC7DfQp5PdEByISDzzmi/Gnvjhu7xPTb0TkZyKSoap+fd3Kzo7OB+OC3asHoLapE7cHphWNIyUl+DMPjsQ5/D1GKN5PpJwvLS2R5fMLeXfvSQ6WNRAT46RkumvEvhSE4ncxGKI17mAaiWvidyO6qh4WkTuBLcB9wJMichL4a1V9c4BdyoHlfZbzgQp/ziUiqcBzeBvQr1bVLt/dyA+Bn6lqT5/iXf6+h5qaZtzu6PpG5nKlUV0d3DptlyuNI+UNpCTGkhBDUIfD6HW+5xjOsB2heD+RcL6+12TWpEzcbjf7S+tw4OGCwswROVewfxeDIRR/Q9HG32vidDoG/eLtbxvINBH5Od7eT7cB3wLygL8CfnuO3V4FVoqIS0SSgc8AL/lzPuBx4BBwg6p2AKiqG7jGdxxEZDXwjqra6G7nqaahjdMN7UxwWfXVaOFwOJgzJYsJOSnsK62n1OYWMUHg7x3IZuBR4EOqerDP+o0i8sZAO6hque+OZR3ebryPqOpmEVkL/L2qvjvQfiIyH7ga2AtsExGAClW9Evgi8LCI/ANwCljtZ/xmEBu2lwNQ6IrOKj4zMIfDwfwLcujs7mHHoRriY2PIt+FpzAjyN4F8XVXX9F0hIl9Q1d+q6i3n2sm3z5p+664coNwtfV5vY+D2E1R1D7DMz5iNn/6ytYzM1HgbeXcUcjodLJ6Ry8bdVWw9UM3yefmkJ8eHOywzSgyaQETkk3gf5vuJiLTx/gd7HN6G7XNVX5koUVnTwuGyBmZPGRfuUEyQxMZ4e2e9saOCLftOsWJeAXGx9qCoOX9D3YGUAB8BcoG/6bO+G29Duolym/acxOmACTn28OBolpgQy0LJ5e3dVWw7eJrFM0auZ5YZuwZNIKr6E7x3H3eo6kMhismEiMfj4Z29J5k7zUVivA2LNtrlZCQya/I49hyr41B5w4j1zDJj11BVWJ/3PdSXJCLf6b9dVf9f0CIzQXe0solT9W187grhaFl9uMMxIVBckE5dUwf7j9fjykwiMzW0z6yY0WWoitALfP/OAS4c4MdEsU17qoiNcbL0woJwh2JCxOFwMHdaNglxMWw7cJoet9/P9hpzlqGqsP7B968NWjjK9LjdbN5/innTskmx3ldjSnxsDCXTstm09xT7j9cze3JWuEMyUWqoKqxdwDkf3VbVuSMekQmJfaV1NLZ0cvGs8eEOxYRB7rhkJo1P5XB5I3lZyWSn2wCaZviGajn9ekiiMCH3zp6TJCXEMneqzWQ3Vs2enEV1fTvbD57msvkFNgeMGbahfmNOquobQNM5fkwU6uzq4b0D1SwUl817PobFxjqZNy2blvZuDpU1hjscE4WGugO5H7gK+N8BtnmA4hGPyATdjsM1tHf2sNSqr8Y8V2YSBdnJHCxvoDA3hZREaw8z/huqEf0q379TQhOOCYVNe6rISI1HiuzpcwOzp2Rxsq6c3Udquci+VJhh8OvpMRFJwTu3+UfxDp++Fvi5qnYGMTYTBC3tXew6UsNHFhTidNqTyAaSEmKRokz2HqujqraVvCwbcNH4x99Ws4fwzib4fbyJZA7vz1NuosiW/afo7vFw8Wz7pmneV5yfTlpSHLuP1NITZXPmmPDxd/yK+X277IrIX4AdQYnIBNXbu6vIz05m0niboc28z+l0MKc4i7f3nORYZSNTJ2SEOyQTBfy9A6kTkb5PG6XinZ/cRJHq+jYOljWwbE6eDaRnzuLKTMKVmciBsgY6u3uG3sGMeUM9SNhbTdUFvCcifwR6gE/hnfDJRJFNe6oArKHUnNOsyVm8sb2Cg2UN9oS6GdJQVVg1vn83+H56PRGccEyweDweNu45iUzMJCcjKdzhmAiVkRLPxNwUjlY0MiUvneREG6XZnNtQ3Xh/fK5tvp5ZgxKRm/A2uscDD6jqg+co9xiwTlUf9S0X4Z0XPRdQ4GZVbRaRTOB3eJ8/qcY7Z3rVUHEYOFbVxMnaVj5+UVG4QzERbkbROMpPt7L/eB0LprvCHY6JYH61gYjI1SKyQ0QOi8gRESkFBv3gFpEJwD3ApcA84KsiMqtfmQIReR64vt/uDwEPqeoM4F3gbt/6fwI2qOpM4GHgl/7Eb2Djbu/Iu4vEPhDM4JISYinOT6OsuoXGFuupb87N30b0+/FOYXscuAN4CfjNEPusAl5X1VpVbQGeAq7rV+Zm4FngD70rRCQOWOErD/Ao7yeYT+C9AwFvNdrHfeXNILp73Gzed5KSC3JItieNjR+mTcggNsaBnqgPdygmgvmbQFpU9ffAJqAd+Gtg5RD7FACVfZYr8T5Lcoaq3qeqj/TbLwdoVNXuAfY7c0zf9kbAvlIPYffRWppau1g2Oy/coZgoER8XQ3F+OpU1rTTYXYg5B39byDpEJAE4BJSo6l98y4MZqJ+oP7PXDLZfoMcEIDs71d+iEcXlOr9nNra9pKQlx3PZkknExQ78nSElJbQz043E+fw9RjS+t0DPN5LnvvACF0ermjhc0cjykgnA+f8uhku0xh1MI3FN/E0gzwIvALcAG0VkOe/30DqXcmB5n+V8oMKPc1UD6SISo6o9/fYrB/KAMhGJBdL9iOOMmppm3FH2lK3LlUZ1deADH7e2d7NpdyXL5+ZTX9dyznO0tHQEfI5AnO/5UlIS/D5GtL23QM83nGvir+L8dPREPeUnvaP1ns/vYric79/QaOTvNXE6HYN+8farCktVfwp8SVXLgKuB9ZzdntHfq8BKEXGJSDLwGbxtJ0Odqwtvl+EbfatWAy/6Xq/1LePbvsFX3pzDe3qKrm43S+dY9ZUZvuKCdOJinejx+nCHYiLQcGaQmSki9wM3ANtU9dRghVW1HLgTWAdsB9ao6mYRWSsii4Y41x14e23txXsXc5dv/d3AxSKyx1fma8OIf0x6e08VueOSKM5PD3coJgrFxTqZWpDOybo2Dp6oC3c4JsL4Oxrv/wE+j7dnlAN4RER+ea7nOnqp6hpgTb91Vw5Q7pZ+y6XAZQOUq8X7FLzxw6m6VvYfr+eaFcU2dIkJ2JT8dA6VN/A/rx3ktk/MDHc4JoL4ewdyE3CRqv69qt4NXIT3DsBEsDd3VeFwwCVWfWXOQ1ysk+L8dN7eVUl5dXO4wzERxN8E0gac+c1R1Tq83XlNhHK7Pby1q5I5U7LJSk8MdzgmyhUXpJMYH8MLm0rDHYqJIEMNpnit76UCz4jII3gHU1yN9wlxE6H2HKulrqmDz628INyhmFEgPi6Gjy2dzLPrD/PpS6eQO84mnTJD34F8w/czAW+X2e8A3wPGA/bJFME27KwkNSmOkgtywh2KGSWuuWwaMU4nazcdD3coJkIMNZjih/su+569cFjX2cjW1NrJtgPVfGRBIbExw+loZ8y5ZaUnsnxuPut3VPCpSyZb1ajxezDFXBF5EWgB2kXkdREpCG5oJlCb9pykx+1h+dz8cIdiRpne0ZxfesfuQoz/jej/inccrPF4h1jfAPw6WEGZwHk8HjbsrGByXhqFudE5dIuJXDmZSVw8ezzrd1TYSL3G7wQyXVV/rKr1qlqjqv8ATAtmYCYwh8sbKatu4bL5E8Idihmlrrx4El3dbl7ZciLcoZgw8zeBxInImQpP39Ak0TWo1BixblsZSQkxLJmZG+5QzCiVn53Cohm5vL61jNZ2aw4dy/xNIE8Cr4rIl0Xky8ArvD9fh4kQTa2dbNlfzdLZeSTG21SkJng+sXQS7Z09vPZeWbhDMWHk72CKPwH+A7gc+BjeSZ7OOd2tCY+3dlXR3eO26isTdEXj05g3NZs/v1tGe2f30DuYUcnfsbBeU9WVwH8FOR4TILfHw1+2l3NBYQaFLms8N8H3iWWT+elv3+ON7RVcsaQo3OGYMPC3CitTRFKCGok5L/tK6zhV12Z3HyZkpk3IYEZRJi9tPk5Xt9/zuplRxN+K8hagVER28sExsWxk3Ajxl63lpCbFsUhshl8TOlctm8z9T27nrV2V9uVlDBoygYjIHLwzEr4MWItZBDrd0MbWg9VcsaSIuNiYcIdjxpCZk8YxJT+dtZtKWT4vnxinjXwwlgw1mOKtwP8FDgJTgZtV9eVQBGb89/rWchw4WLmgMNyhmDHG4XBw1bJJ/Mv/7mLz3lM28+UYM9TXhb8B5qjqRcAngR8EPyQzHB2dPazfXsECcZGdYWMTmdCbNy2HQlcKL2wqxe2xx8PGkiHvN1W1wvfv24BVsEeYjbsrae3o5vJFE8MdihmjnA4HVy6dRMXpFrYdqA53OCaEhmoD6f91YlgdvkXkJrzzmccDD/SfAldESoCHgQxgPXA7kIX3QcVeGYBLVVNFZAXwNNA7hsI2Vb11ODGNJm6Phz+/W8aU/DSmTrA5z034LJkxnmc2HOVPG0tZMN1lUyiPEcNt8fL7/lREJgD3AJcC84CvisisfsUeB76hqtPxzrV+m6qeUtUSVS0BFgDHgK/6yi8G7u/dPpaTB8DuI7VU1bby0UUT7Q/WhJXT6eDKiydRerKJPUdrwx2OCZGh7kDmikhjn+Vk37ID8KjqYF97VwGvq2otgIg8BVwH/KNveRKQpKqbfOUfxft0e99Rfm8FWlV1jW95MZArIjfgvQv5mqqO2RHd/vzuCTJS41k0w8a9MuG3bE4ez755lD9tPMac4uxwh2NCYKg7kKnAhX1+epfn+P4dTAFQ2We5Eij0d7uIxOCt/vq7PmXqgV+q6nxgLd4xusak475veitt0igTIWJjnHzsoiIOlDVw4ER9uMMxITDUjISl53HsgepU3MPY/jHggKru6hPP7X1e/0ZEfiYiGara4E9A2dnROcSHy5V21rpHX1aSEmK5/vIZpCbFnfc5UlISzvsYoT6fv8eIxvcW6PmCfe6Bfhf7unbldNZuKuWV98q4ZEHkdOwYKu6xaCSuSTCHbC0HlvdZzgcq+m3PG2T7p+lzhyEiTuCHwM9UtadPOb/Hk66pacbtjq5uhi5XGtXVTR9Yd6q+jQ3by7liSRFtze20Nbef9zlaWjrO6xjDdb7nS0lJ8PsY0fbeAj3fcK5JoPr/Lg5k1cJC/veNI2zeWc6U/PB37hjob2is8/eaOJ2OQb94B7Pu41VgpYi4fPOHfAZ4qXej7+6mXUQu8a1aDbzYZ/+leGc+7C3vBq7xHQcRWQ28o6qtQXwPEenld44T43TwUeu6ayLQRxYUkpIYy7NvHg13KCbIgpZAVLUcuBNYB2wH1qjqZhFZKyKLfMVuBh4QkX1ACvCrPoco5uyhU74IfEtE9uBtYP9KsOKPVA0tnby5q5Jlc/IZlxbaqhJj/JGUEMvHLipi5+EaDpf7VbtsolRQZx3y9Z5a02/dlX1e7wCWnGPf5AHW7QGWjXCYUeXVd0/Q3e3m4xfZ8Nkmcq1cWMgrW07wzIYjfPez88MdjgkS674TRVrbu3h9azkLxcX4rLPyqzERIzE+lo9fNIk9x+qsR9YoZgkkivz53TLaOrq5atnkcIdizJA+vGACGSnxPL3+CB4bI2tUsgQSJVrbu3hlywkWTHdRNN66JJrIlxAXw5VLJ6En6tlbWhfucEwQWAKJEr13H5+6ZHK4QzHGb5eVFJCdnsBT6w7bSL2jkCWQKGB3HyZaxcXGcO2KqZSebGLz3pPhDseMMEsgUcDuPkw0u2j2eIpyU/nj+iM2d/ooYwkkwjW1dtrdh4lqToeD6z88jdMN7azbarNijyaWQCLcU68dpL2jm09fOiXcoRgTsNlTspg9JYvnNx6jpd3v0YdMhLMEEsFqG9t5/s0jLJ2TR2FudA4EaUyv6y+bSmt7N8+9eSzcoZgRYgkkgj2z4SgeD3x6ud19mOhXND6NFSUFvPZeGeXVzeEOx4wASyARqry6mbd2V3LVpVPIyUgKdzjGjIhrVxSTlBDD7/58wB4uHAWCOhaWCUxGZjL/9vxe73wfK6eTnhIf7pCMGRFpyfFcu6KY375ygC37T7Fk5vhwh2TOgyWQCHTwRD3v7KliRlEmf3rzSNDneLjt2nlBPb4xfX2oZAJvbK/g968fYt7UHBLiY8IdkgmQVWFFGI/Hw2Mv7CUhLobigvBPxmPMSHM6Hdx8+XTqmjpszpAoZwkkwmw/dJp9x2qRokyb69yMWhcUZrJiXgEvbznO0crGcIdjAmSfUBGku8fNH9YdZoIrlaLx1m3XjG43fHgamakJ/OfafXT32BPq0cgSSAR57b0yTta28pWr5+B0OMIdjjFBlZwYyxeuEMqrW/jTxmPhDscEwBJIhGhs6eS5t45yYXE2i6xnihkjSqblcPGs8bzwdillp+zZkGgT1F5YInITcBcQDzygqg/2214CPAxkAOuB21W1W0RWAz8HeofvfEFV7xSRIuBxIBdQ4GZVHRW/dX9cf4TOLjefXTkt3KEYE1KfW3UBe4/V8u/P7+HuLy4iLtZ6ZUWLoN2BiMgE4B7gUmAe8FURmdWv2OPAN1R1OuAAbvOtXwx8R1VLfD93+tY/BDykqjOAd4G7gxV/KJVWNbFhRwUrFxaSn50S7nCMCam05Hi+9IlZlFW38IfXD4c7HDMMwazCWgW8rqq1qtoCPAVc17tRRCYBSaq6ybfqUeB63+vFwGoR2SEij4vIOBGJA1b4jtO/fNTyeDw88eoBUpLibLh2M2bNnZrN5Ysn8trWMrYfPB3ucIyfglmFVQBU9lmuBJYMsb2wz+ufAZuBnwL/Cvwt0Kiq3QOU90t2duT1bNqwvZwDZQ187bp5TJqYdWZ9SkrCgK+DJRTnGOnz+XuMaHxvgZ4vmOfu6XHjcgVvSoHbr5vHoYpG/uvF/fzL7MvITE0gZoS6sgcz7mg1EtckmAlkoG5Ebn+2q+o1vStE5F7gCPC9IY43pJqaZtzuyBl/p6Orh/94dhcTc1OZX5xFdXUT4P2P7X36PCUlIehPogMhOcdInm841yXa3lug5wv270pMjJOH/7gjaMcHmJybSmllI9/5xRs8cufl1Pr+Js6Hy5V25m/LePl7TZxOx6BfvINZhVUO5PVZzgcqhtouIhki8u0+6x1AF1ANpItITN/yIx51CL3w9jFqGju4adUFOJ3WbdeY1OQ4SqZlU9vYwcPP7gp3OGYIwUwgrwIrRcQlIsnAZ4CXejeqainQLiKX+FatBl4EmoHvi8hFvvVfB55W1S5gA3Bjv/JRqbKmhRc3HWfp7DykaFy4wzEmYkxwpTJtQjovbjzG+h1R/R1x1AtaAlHVcuBOYB2wHVijqptFZK2ILPIVuxl4QET2ASnAr1S1B7gB+LVv/ULg+77yd+DtzbUXWI63i3DU8Xg8/PZlJSEuhhs+Yt12jelv5qRxzJ/u4rcvK4fKG8IdjjmHoD4HoqprgDX91l3Z5/UOPtiw3rt+A7BggPWlwGUjHmiIbdp7kv3H6/nC5dPJsKHajTmLw+Hge19YxLf+71/41VM7uXP1QsaPSw53WKYfexI9xFrbu/j9aweZkp/Gh0omhDscYyJWWnI837rBO9XAA7/fQWNLZ5gjMv1ZAgmxP64/QlNbF6uvmGEN58YMIS8rmW9eN5f65g5+8T87aO/sHnonEzKWQELoaGUj67aW85EFhUzKs37pxvhj6oQMbr96DqUnm3jo6d10ddvIvZHCEkiI9Ljd/PdLSnpKPNcsLw53OMZElZILcrjlYzPYfbSWXz+z24Z/jxCWQELklS0nKD3ZxE0fnU5yos0kbMxwLZ9XwBcun872Q6f5t+f20OO2JBJu9knmp4zMZOLjAhsltKK6mWc3HOXiOXl8/NJiHDbXhzFDGmjolBuumEliUjwPP7ubx14+wHduWkhc7NDfg/0ZtqOzq4eG+taA4x2LLIH4KT4uJqBhHDweDxt3V+H2eEhPiuWRp3cOuc9t184LJERjRpXBhk6ZNXkcb+6o4MDxOhaJa9Dpn/0d4sX+7obPqrCCrPRkMzWNHcyZkkVivOVrY0bCtAkZzJ2azam6NjbtPWkN62FiCSSI2jq62XuslpyMRCbmRt5IwMZEs8l5aSyc7qKuqYONu6vo6OoJd0hjjiWQIPF4POw8XIPHA/OmZVu7hzFBMMGVwpIZuTS1dfHWripaO+w5kVCyBBIk5dUtnKxrY8akTFIS48IdjjGj1visZJbOGk97ZzcbdlRS3xza4fTHMksgQdDW0c3OIzWMS0ugOD893OEYM+plZyRy6dx8nE54a1cVVTXWmyoULIGMMI/Hw7aDp/F4YMH0HKu6MiZE0pPjWT43n7TkODbvP8WRikY8nsiZQG40sgQywo5UNnK6oZ05xVlWdWVMiCXGx7JsTh55WcnsPlrLriO1ETUL6WhjCWQENbZ2su9YHXlZSRRZrytjwiI2xsniGS6mFqRzrKqJde+VWQ+tILEEMkLcbg9bD5wmNtbJvKlWdWVMODkcDmZPyWL+BTmcbmhj/Y4KGqxxfcRZAhkheqKexpZOSqbmkBAf2JAnxpiRNTE3lVWLi/B44M1dVZRVN4c7pFElqI9Gi8hNeKedjQceUNUH+20vAR4GMoD1wO2q2u2bJ/0XQBxQA3xJVUtFZAXwNHDCd4htqnprMN+DP6rr2zhY1kBRbip52TZrmjGRJDsjkRXzCnhXT7H1wGnqmzqZNXmczcczAoJ2ByIiE4B7gEuBeXjnMp/Vr9jjwDdUdTrgAG7zrf8d8GVVLfG9/pVv/WLgflUt8f2EPXm0d3az9UA1qUlxzCnOCnc4xpgBJMbHsGx2HlPy0zhS2chbuyppbbeHDs9XMKuwVgGvq2qtqrYATwHX9W4UkUlAkqpu8q16FLheRBKAu1S1d9TBnUCR7/Vi4KMisk1EnhORiUGMf0gej7fdo7vHw6IZgw/oZowJL6fTwYXF2SwSF01tXbyxvcKeFzlPwfzEKwAq+yxXAoVDbVfVDlV9HEBEnMCPgGd8ZeqBX6rqfGAt8GQwAvfXgRMNnG5o58LiLNKT48MZijHGTwU5KXxoXgHJibFs3n+K3Udr6bGuvgEJZhvIQBWMbn+3i0g88BjeGH8KoKq3925X1d+IyM9EJENVG/wJKDv7/LrWpqQknHldUd2Mnqhncn46M6aM/FhXfc/V93WwhOIcI30+f48Rje8t0PMF+9zRei37HyclJYErspLZptUcPFFPbWMHH7ukkcljaOQIf+ZIGUowE0g5sLzPcj5Q0W973kDbRSQVeA5vA/rVqtrluxv5IfAzVe3bqbvL34BqapoDfqjI5Uo7M6dAc1sXb+2sID0lnlmTMmlt7QzomIPpPZe/cxmM1PlC5XzPN5zrEm3vLdDzheJ3JRqv5WDXZWZRJuNS49l+6DTffuANrlk+hSuWFI36BnaXK43q6qYhyzmdjkG/eAezCutVYKWIuEQkGfgM8FLvRlUtBdp9Pa4AVgMv+l4/DhwCblDVDl95N3CN7ziIyGrgHVUNaSVmV7ebzftO4XQ4WGLtHsZEvbysZD48fwKLZ43nf/5ymJ+v2cqpOmsb8UfQPv1UtRy4E1gHbAfWqOpmEVkrIot8xW4GHhCRfUAK8CsRmQ9cDVwCbBOR7SKy1lf+i8C3RGQPcCvwlWDFPxDvOFfVtLR1sWiGi2QbqsSYUSEhLoYffnExX7lqJmXVzdz9H5t5fuMxm6hqCEF9DkRV1wBr+q27ss/rHcCSfrttY+D2EVR1D7BshMP0256jdVTVtjFnShY5GUnhCsMYEwQOh4Nlc/KZUTSOJ187yNPrj/D27iq+cPl0Zk62LvoDsfoXPz3zxmGOVDZSnJ/GlPzzb3wyxkSmrPRE7rjmQr59wzx63G7ue3I7//7cHmob28MdWsSxSbr9sHnfSf7juT3kZycze0qWjXNlzBhwYXE2P/nyRazdVMraTcd5V6tZtbCQK5dOIjXJqq/BEsiQOjp7eORP+5g5OYvivFRLHsaMIfFxMXx6eTGXzs3n2Q1HeXnzcd7YUcGqhYWsWlRI2hh//ssSyBDi45zc9slZrFhUxBMv7g13OMaYMMjJSOLLV83iiiVFPL3hCM9vPMbLW46zYl4BH100EVfm2GwTtQQyBIfDweIZuXbLaoyhMDeVb3xmLuWnW3hxUynrtpbz2rtlzCnO5rL5Bcydmk2Mc+w0LVsCMcaYYZqQk8JXrprFtSuKWb+jgvU7KviX/91FenIci2eO5+LZ4ynOTz9nlXdGZjLxcaGb9qGzq4eG+pF/tsUSiDHGBCgrPZFPLy/mqmWT2Xm4hrf3VPHG9gpee6+McWkJXFiczdyp2cyaPI7E+Pc/buPjYnj4jztCFudt184LynEtgRhjzHmKjXGyYLqLBdNdtLZ3s+1gNdsPnWbzvpOs31FBbIyD6RMzkYmZTJ+YSXrm6Jg3yBKIMcaMoOTEWC65MJ9LLsynu8fNwbIGdh4+zZ6jtTy94SgAsb/fQXpyHOPSEshMSyAzNZ7khNio6+VpCcQYY4IkNsbJzEnjmDlpHOAdiPVQWQNlNa2se+8ERysbcfuGmI2LdZKZGk9masKZfxPjYyI6qVgCMcaYEElNiqPkghw+uiyN7q5u3G4Pja2d1Dd3Ut/cQX1zJ4fKGugdMzwhzulLKAneu5XU+JA2vg/FEogxxoSJ0+k4kyDAO0RST4+bxtYu6ps7qGvqoKG5k5N1bWf2SUmM/UBCyUiJJyZMo4JbAjHGmAgSE+NkXJo3QUzJ967r6nbT0NxBXXMndU0d1DS2U366BQCHA9KT48/sk5WWQHJiaNpTLIEYY0yEi4t1kpOZRE6fJ97bOrrPVHvVNXVQVt3MsSrvJFEJcU7GpSWSlZ5AVnoCPT3BGZbeEogxxkShpIRYkhJiyc9OAbzzFTW1dlHb1EFtYzu1TR1U1XofHhz/4j4+cVHRiMdgCcQYY0YBh8NBeko86SnxTM7ztqe0d3ZT19TJx5ZOBvfI34VYAjHGGLyN1y7X6JrrJzE+lvzsWPKyU/yaA324LIEYYwzexutQDS8SrKFFQi2oCUREbgLuAuKBB1T1wX7bS4CHgQxgPXC7qnaLSBHwOJALKHCzqjaLSCbwO6AYqAZuUNWqYL4HY4wxAwta52ERmQDcA1wKzAO+KiKz+hV7HPiGqk7HOw/6bb71DwEPqeoM4F3gbt/6fwI2qOpMvInnl8GK3xhjzOCCeQeyCnhdVWsBROQp4DrgH33Lk4AkVd3kK/8o8GMReQRYAXy6z/o3gB8An/BtA3gCeFBE4lS1a4hYYsD70M75SE0O3ZwgvedKTozD4QlOF7yBzhcq53u+4VyXaHtvgZ4vFL8r0XgtI/V3JdTXsv/nnz+fh33KDPj4u8Pj8Qy0/ryJyA+BFFW9y7f8FWCJqn7Vt7wUuE9VL/UtTwPWAh8CtqhqoW99LNCqqvEi0uE7ZrdvW5nvmBVDhHMpsGHE36QxxowNy4E3+68M5h3IQOnN7cf2wfYb6pjnsgXvBagEevwob4wxxnvnkY/3M/QswUwg5Xg/tHvlAxX9tucNsL0aSBeRGFXt6bdf7z5lvjuTdKDGj1g6GCB7GmOMGdLhc20I5ghcrwIrRcQlIsnAZ4CXejeqainQLiKX+FatBl70tWdsAG7su973eq1vGd/2DX60fxhjjAmCoCUQVS0H7gTWAduBNaq6WUTWisgiX7GbgQdEZB+QAvzKt/4OvL229uK9i7nLt/5u4GIR2eMr87VgxW+MMWZwQWtEN8YYM7qFZxB5Y4wxUc8SiDHGmIBYAjHGGBMQSyDGGGMCYqPxRgERuQ9wqeot4Y4l3ETkdWA80Nt9+69U9Z0whhQRROSTwI/w9mZ8WVW/Gd6Iwss38sXX+6yaAvxWVb9+jl3GDBH5PPBD3+KLqvq3gR7LemFFOBFZCTwJvDDWE4iIOPA+TFrUO5yNAREpxvvs1EXASeB14Keq+uKgO44RIjIbeAZYqqqnwxxOWPmeySsDpgP1wFvAnar6aiDHsyqsCCYiWXhHNP5puGOJEAJ4gBdFZIeIjPlvkz7XAL9X1TLfg7U3AmP+rqyPXwP/Z6wnD58YvJ/7KUCc76ct0INZAols/4b3Ycy6cAcSIcYBr+EdqXklcLuIfDSsEUWGaUCMiLwsIjvwPmRrvzOAiKzCO+r3/4Q7lkigqk14H8jej/du/hiwMdDjWQKJUL463BOq+lq4Y4kUqvq2qq5W1Rbft8n/AK4Md1wRIBbv9AmfBy4GlgBfDGtEkeOvgP8X7iAihYjMBb4ETMI7zmAPEHAbiCWQyHUjcLmIbMc7h8qnROSB8IYUXiJyqa9NqJeD9xvTx7Iq4FVVrVbVNrz1/UvCG1L4iUg83ukhngt3LBHkCuA1VT2lqh1451u6LNCDWS+sCKWqZ6pmROQW4DJV/Xb4IooImcA/isgyvHW3XwRuD2tEkeFPwGO+KZ+bgI/jTSJj3VzggKq2hDuQCLIDuFdEUoBW4JOcY6h2f9gdiIkaqvon4AVgG/Ae8J+q+nZ4owo/Xzfme/FOWbAXKAX+K6xBRYZivD2OjI+qvoJ3Ntf3gJ14v4j9LNDjWTdeY4wxAbE7EGOMMQGxBGKMMSYglkCMMcYExBKIMcaYgFgCMcYYExB7DsSYcxCRycBhYFef1Q7gl6r6nwOU/xSwSlX/ZoTOnwY8hXfoll8Du1X1/gCP9U2gTlX/eyRiMwYsgRgzlDZVLeldEJEJwG4ReVdVd/YtqKrPMbJPPf8ceFhV20TkfI/1r8AWEXlFVavOPzRjLIEYMyyqWi4iB4HpIrIA+DLekU0bgMeA61T1KhHJA34DzADcwG9U9VcikgH8ErgQ70NcrwHf6z88vYhMBK4CzrqbEZHlwH1AMtAJ3KWqL4lIjG/9p3zxvAPMUtXLVLVHRP4A/AAY6yMamBFibSDGDIOILMU7+m3vcOmz8Q4z8+F+RR/CO4zGDGAp8FURmQY8ALynqguB+UAO8J0BTnU18PoAiSUbb7XWN1V1Lt7hXB4XkSnAV4CFwBzfOaf2O+bzwLXDf9fGDMzuQIwZXJJvQEvw/r2cBm5W1RO+aqWdqto4wH6rgO8DqGoD3g91ROQqYImIfLn3+Oc47wzg0ADrLwIO9c7CqKp7ROQtvAPiXQn8t6q2+871b3zwDuYwUCQiib1ljDkflkCMGdwH2kAG0HyO9d14J78CzswaeBrvhD7Xq+o+3/rMvuX6cPvK9jdQrYETb3VYN95G/l49/crF+M7lPkfMxgyLVWEZExyvArcC+No9XgMuAF4Gvi0iDhFJwNvoPtDMigfwDgbY3ybvIWWJ79izgRXAX/AONPl5EUkQkVjgFj6YnIqBo6raed7vzhgsgRgTLF8HZorITrzzTv+zqr6Ht0opBW/X4J2+f+8dYP9ngA/7GsbP8E2kdT3wLyKyC1gD3KqqB/DO7fAO3tGKN+JtYG/ts/vHAJuZz4wYG43XmAglIv+Od6KoP/hZ/nIgV1Uf9y3/EmhX1R/4EtFW4HJVPRm0oM2YYncgxkSu7+PtvXWuhvb+9gBfFJEdIrIHcAE/9W37G+AXljzMSLI7EGOMMQGxOxBjjDEBsQRijDEmIJZAjDHGBMQSiDHGmIBYAjHGGBMQSyDGGGMC8v8B4qmJemrsBAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.histplot(data=listings_df, x='price_log', kde=True, stat='probability')\n",
    "fig.set_xlabel('Price (log)')\n",
    "fig.get_figure().savefig('figures/price_kde_histogram.jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate doc2vec embeddings from the descriptions of the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [document.split(' ') if type(document) is str else [] for document in listings_df.description.values]\n",
    "document_embeddings = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents)]\n",
    "model = Doc2Vec(document_embeddings, vector_size=100, window=3, min_count=2, workers=4)\n",
    "fname = get_tmpfile(\"doc2vec_model\")\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 851.00it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_inference = {}\n",
    "for i, document in enumerate(tqdm(documents)):\n",
    "    doc_inference[i] = model.infer_vector(document).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the graph of listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:03<00:00, 63.31it/s]\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "distance_threshold_in_meters = 200\n",
    "document_similarity_threshold = 0.95\n",
    "edges = set()\n",
    "for i, rowi in enumerate(tqdm(listings_df.itertuples(), total=listings_df.shape[0])):\n",
    "    for j, rowj in enumerate(listings_df.itertuples()):\n",
    "        idi = rowi.id\n",
    "        idj = rowj.id\n",
    "        doc_embedding_i = doc_inference[i]\n",
    "        doc_embedding_j = doc_inference[j]\n",
    "        G.add_nodes_from([\n",
    "            (idi, {'y': [rowi.price_log], 'x': [getattr(rowi, feature) for feature in features] + doc_embedding_i}),\n",
    "            (idj, {'y': [rowj.price_log], 'x': [getattr(rowj, feature) for feature in features] + doc_embedding_j})\n",
    "        ])\n",
    "        \n",
    "        distance = hs.haversine((rowi.latitude, rowi.longitude), (rowj.latitude, rowj.longitude), unit='m')\n",
    "        cosine_document_similarity = spatial.distance.cosine(doc_embedding_i, doc_embedding_j)\n",
    "        if distance > distance_threshold_in_meters or cosine_document_similarity < document_similarity_threshold:\n",
    "        #if distance > distance_threshold_in_meters:\n",
    "            continue\n",
    "        fst = np.min([idi, idj])\n",
    "        snd = np.max([idi, idj])\n",
    "        edge_key = f'{fst}-{snd}'\n",
    "        if edge_key in edges:\n",
    "            continue\n",
    "        edges.add(edge_key)\n",
    "        G.add_edges_from([(fst, snd, {'weight': distance})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of node attributes 114\n",
      "number of edges 0\n",
      "number of nodes 200\n",
      "average degree 0.0\n"
     ]
    }
   ],
   "source": [
    "print('number of node attributes %s' % len(nx.get_node_attributes(G, 'x')[13131]))\n",
    "print('number of edges %s' % G.size())\n",
    "print('number of nodes %s' % (len(G)))\n",
    "x = G.degree()\n",
    "x = list(dict(x).values())\n",
    "print('average degree %s' % (sum(x)/len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph into PyTorch geometric\n",
    "pyg_graph = from_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data \n",
    "train_ratio = 0.67\n",
    "num_nodes = pyg_graph.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "random.Random(5).shuffle(idx)\n",
    "\n",
    "train_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "train_mask[idx[:num_train]] = True\n",
    "test_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "test_mask[idx[num_train:]] = True\n",
    "\n",
    "dataset = pyg_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model - GCNBnB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.normalizer = norm.BatchNorm(dataset.num_node_features)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 100)\n",
    "        self.linear1 = torch.nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.normalizer(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss function 5.572031497955322\n",
      "epoch 1, loss function 4.060911178588867\n",
      "epoch 2, loss function 2.8270013332366943\n",
      "epoch 3, loss function 2.8897807598114014\n",
      "epoch 4, loss function 3.166910171508789\n",
      "epoch 5, loss function 2.948481798171997\n",
      "epoch 6, loss function 2.519646167755127\n",
      "epoch 7, loss function 2.443653106689453\n",
      "epoch 8, loss function 2.5422003269195557\n",
      "epoch 9, loss function 2.5123326778411865\n",
      "epoch 10, loss function 2.2710225582122803\n",
      "epoch 11, loss function 2.1242129802703857\n",
      "epoch 12, loss function 2.121514081954956\n",
      "epoch 13, loss function 2.071000337600708\n",
      "epoch 14, loss function 1.9382492303848267\n",
      "epoch 15, loss function 1.808683156967163\n",
      "epoch 16, loss function 1.676370620727539\n",
      "epoch 17, loss function 1.568138837814331\n",
      "epoch 18, loss function 1.480207085609436\n",
      "epoch 19, loss function 1.3467274904251099\n",
      "epoch 20, loss function 1.1788036823272705\n",
      "epoch 21, loss function 1.1349807977676392\n",
      "epoch 22, loss function 1.0897715091705322\n",
      "epoch 23, loss function 0.9195923805236816\n",
      "epoch 24, loss function 0.8137413859367371\n",
      "epoch 25, loss function 0.84392249584198\n",
      "epoch 26, loss function 0.7380993366241455\n",
      "epoch 27, loss function 0.7267012000083923\n",
      "epoch 28, loss function 0.7426928281784058\n",
      "epoch 29, loss function 0.674543023109436\n",
      "epoch 30, loss function 0.7077017426490784\n",
      "epoch 31, loss function 0.6647626757621765\n",
      "epoch 32, loss function 0.591385006904602\n",
      "epoch 33, loss function 0.5954434871673584\n",
      "epoch 34, loss function 0.5292295813560486\n",
      "epoch 35, loss function 0.5886147618293762\n",
      "epoch 36, loss function 0.5296812653541565\n",
      "epoch 37, loss function 0.5442965626716614\n",
      "epoch 38, loss function 0.5399062633514404\n",
      "epoch 39, loss function 0.4357183575630188\n",
      "epoch 40, loss function 0.4928928017616272\n",
      "epoch 41, loss function 0.4541988670825958\n",
      "epoch 42, loss function 0.442924439907074\n",
      "epoch 43, loss function 0.43383708596229553\n",
      "epoch 44, loss function 0.40990355610847473\n",
      "epoch 45, loss function 0.4372209906578064\n",
      "epoch 46, loss function 0.3819054365158081\n",
      "epoch 47, loss function 0.4398031532764435\n",
      "epoch 48, loss function 0.4365589916706085\n",
      "epoch 49, loss function 0.3490941524505615\n",
      "epoch 50, loss function 0.42785683274269104\n",
      "epoch 51, loss function 0.3348624110221863\n",
      "epoch 52, loss function 0.35463371872901917\n",
      "epoch 53, loss function 0.3474677801132202\n",
      "epoch 54, loss function 0.3198091685771942\n",
      "epoch 55, loss function 0.38772833347320557\n",
      "epoch 56, loss function 0.29440996050834656\n",
      "epoch 57, loss function 0.3654009699821472\n",
      "epoch 58, loss function 0.37114042043685913\n",
      "epoch 59, loss function 0.2785505950450897\n",
      "epoch 60, loss function 0.37979114055633545\n",
      "epoch 61, loss function 0.2569488286972046\n",
      "epoch 62, loss function 0.3978617489337921\n",
      "epoch 63, loss function 0.27870917320251465\n",
      "epoch 64, loss function 0.38188591599464417\n",
      "epoch 65, loss function 0.277667760848999\n",
      "epoch 66, loss function 0.3639891445636749\n",
      "epoch 67, loss function 0.3116156756877899\n",
      "epoch 68, loss function 0.3500210642814636\n",
      "epoch 69, loss function 0.31865930557250977\n",
      "epoch 70, loss function 0.3127898871898651\n",
      "epoch 71, loss function 0.3300984501838684\n",
      "epoch 72, loss function 0.3143361210823059\n",
      "epoch 73, loss function 0.27514350414276123\n",
      "epoch 74, loss function 0.2832848131656647\n",
      "epoch 75, loss function 0.2853822708129883\n",
      "epoch 76, loss function 0.23949044942855835\n",
      "epoch 77, loss function 0.2741979956626892\n",
      "epoch 78, loss function 0.2396167367696762\n",
      "epoch 79, loss function 0.25049856305122375\n",
      "epoch 80, loss function 0.24591544270515442\n",
      "epoch 81, loss function 0.21768595278263092\n",
      "epoch 82, loss function 0.24531890451908112\n",
      "epoch 83, loss function 0.19295477867126465\n",
      "epoch 84, loss function 0.24298095703125\n",
      "epoch 85, loss function 0.2037353515625\n",
      "epoch 86, loss function 0.2459840327501297\n",
      "epoch 87, loss function 0.2888026237487793\n",
      "epoch 88, loss function 0.22589297592639923\n",
      "epoch 89, loss function 0.35145384073257446\n",
      "epoch 90, loss function 0.2875385582447052\n",
      "epoch 91, loss function 0.35933902859687805\n",
      "epoch 92, loss function 0.26654285192489624\n",
      "epoch 93, loss function 0.37034139037132263\n",
      "epoch 94, loss function 0.17876413464546204\n",
      "epoch 95, loss function 0.34772053360939026\n",
      "epoch 96, loss function 0.18456272780895233\n",
      "epoch 97, loss function 0.30230867862701416\n",
      "epoch 98, loss function 0.286292165517807\n",
      "epoch 99, loss function 0.24859973788261414\n",
      "epoch 100, loss function 0.30454838275909424\n",
      "epoch 101, loss function 0.2706146240234375\n",
      "epoch 102, loss function 0.37813055515289307\n",
      "epoch 103, loss function 0.4262314736843109\n",
      "epoch 104, loss function 0.18554285168647766\n",
      "epoch 105, loss function 0.3353574275970459\n",
      "epoch 106, loss function 0.16718658804893494\n",
      "epoch 107, loss function 0.3318385183811188\n",
      "epoch 108, loss function 0.18118929862976074\n",
      "epoch 109, loss function 0.32225915789604187\n",
      "epoch 110, loss function 0.2709842920303345\n",
      "epoch 111, loss function 0.2792491018772125\n",
      "epoch 112, loss function 0.2698531150817871\n",
      "epoch 113, loss function 0.3394910395145416\n",
      "epoch 114, loss function 0.24089817702770233\n",
      "epoch 115, loss function 0.30638858675956726\n",
      "epoch 116, loss function 0.24798691272735596\n",
      "epoch 117, loss function 0.24931849539279938\n",
      "epoch 118, loss function 0.20965564250946045\n",
      "epoch 119, loss function 0.2890563905239105\n",
      "epoch 120, loss function 0.2224290370941162\n",
      "epoch 121, loss function 0.32114461064338684\n",
      "epoch 122, loss function 0.27541908621788025\n",
      "epoch 123, loss function 0.2741389870643616\n",
      "epoch 124, loss function 0.2492319941520691\n",
      "epoch 125, loss function 0.2753369212150574\n",
      "epoch 126, loss function 0.2540150284767151\n",
      "epoch 127, loss function 0.24658675491809845\n",
      "epoch 128, loss function 0.2629648447036743\n",
      "epoch 129, loss function 0.19135569036006927\n",
      "epoch 130, loss function 0.24050994217395782\n",
      "epoch 131, loss function 0.21460875868797302\n",
      "epoch 132, loss function 0.20775018632411957\n",
      "epoch 133, loss function 0.2445492148399353\n",
      "epoch 134, loss function 0.17711958289146423\n",
      "epoch 135, loss function 0.25302284955978394\n",
      "epoch 136, loss function 0.2107558250427246\n",
      "epoch 137, loss function 0.21097929775714874\n",
      "epoch 138, loss function 0.21288496255874634\n",
      "epoch 139, loss function 0.16286735236644745\n",
      "epoch 140, loss function 0.20284053683280945\n",
      "epoch 141, loss function 0.1566903442144394\n",
      "epoch 142, loss function 0.2172987461090088\n",
      "epoch 143, loss function 0.16053873300552368\n",
      "epoch 144, loss function 0.22801993787288666\n",
      "epoch 145, loss function 0.1736806333065033\n",
      "epoch 146, loss function 0.20178157091140747\n",
      "epoch 147, loss function 0.21143566071987152\n",
      "epoch 148, loss function 0.13069599866867065\n",
      "epoch 149, loss function 0.24005214869976044\n",
      "epoch 150, loss function 0.16940738260746002\n",
      "epoch 151, loss function 0.22329245507717133\n",
      "epoch 152, loss function 0.26137664914131165\n",
      "epoch 153, loss function 0.12001689523458481\n",
      "epoch 154, loss function 0.26240304112434387\n",
      "epoch 155, loss function 0.25751397013664246\n",
      "epoch 156, loss function 0.11915461719036102\n",
      "epoch 157, loss function 0.20077203214168549\n",
      "epoch 158, loss function 0.15816310048103333\n",
      "epoch 159, loss function 0.21560969948768616\n",
      "epoch 160, loss function 0.20413777232170105\n",
      "epoch 161, loss function 0.14507168531417847\n",
      "epoch 162, loss function 0.22728747129440308\n",
      "epoch 163, loss function 0.12658432126045227\n",
      "epoch 164, loss function 0.21231263875961304\n",
      "epoch 165, loss function 0.19694116711616516\n",
      "epoch 166, loss function 0.15911395847797394\n",
      "epoch 167, loss function 0.1920899897813797\n",
      "epoch 168, loss function 0.1181202232837677\n",
      "epoch 169, loss function 0.15933477878570557\n",
      "epoch 170, loss function 0.12267139554023743\n",
      "epoch 171, loss function 0.19557422399520874\n",
      "epoch 172, loss function 0.16381575167179108\n",
      "epoch 173, loss function 0.16685260832309723\n",
      "epoch 174, loss function 0.1275417059659958\n",
      "epoch 175, loss function 0.16301651298999786\n",
      "epoch 176, loss function 0.15416455268859863\n",
      "epoch 177, loss function 0.14504727721214294\n",
      "epoch 178, loss function 0.16969706118106842\n",
      "epoch 179, loss function 0.15611043572425842\n",
      "epoch 180, loss function 0.13406741619110107\n",
      "epoch 181, loss function 0.16995571553707123\n",
      "epoch 182, loss function 0.1213097870349884\n",
      "epoch 183, loss function 0.18659904599189758\n",
      "epoch 184, loss function 0.15880009531974792\n",
      "epoch 185, loss function 0.16828368604183197\n",
      "epoch 186, loss function 0.11748167127370834\n",
      "epoch 187, loss function 0.1694587767124176\n",
      "epoch 188, loss function 0.14843952655792236\n",
      "epoch 189, loss function 0.1205580085515976\n",
      "epoch 190, loss function 0.11738662421703339\n",
      "epoch 191, loss function 0.15059533715248108\n",
      "epoch 192, loss function 0.16480080783367157\n",
      "epoch 193, loss function 0.16674482822418213\n",
      "epoch 194, loss function 0.13575348258018494\n",
      "epoch 195, loss function 0.09969846159219742\n",
      "epoch 196, loss function 0.11084497720003128\n",
      "epoch 197, loss function 0.1913066804409027\n",
      "epoch 198, loss function 0.10427685081958771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199, loss function 0.15834620594978333\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "epoch_loss = []\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.step()\n",
    "    out = model(data)\n",
    "    loss = F.l1_loss(out[train_mask].squeeze(), data.y[train_mask].squeeze())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    print('epoch {}, loss function {}'.format(epoch, loss.item()))\n",
    "    epoch_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:0.260792114812177\n",
      "mse:0.3895061133708721\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred = model(data)\n",
    "    y_true = data.y[test_mask].tolist()\n",
    "    y_pred = pred[test_mask].tolist()\n",
    "    print('r2:%s' % r2_score(y_true, y_pred))\n",
    "    print('mse:%s' % mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss function 5.55695104598999\n",
      "epoch 1, loss function 5.498366832733154\n",
      "epoch 2, loss function 5.514894485473633\n",
      "epoch 3, loss function 5.490368843078613\n",
      "epoch 4, loss function 5.505905628204346\n",
      "epoch 5, loss function 5.454981327056885\n",
      "epoch 6, loss function 5.479246139526367\n",
      "epoch 7, loss function 5.472354412078857\n",
      "epoch 8, loss function 5.476804256439209\n",
      "epoch 9, loss function 5.430298328399658\n",
      "epoch 10, loss function 5.421919822692871\n",
      "epoch 11, loss function 5.402451992034912\n",
      "epoch 12, loss function 5.39597749710083\n",
      "epoch 13, loss function 5.366254806518555\n",
      "epoch 14, loss function 5.363675117492676\n",
      "epoch 15, loss function 5.339900016784668\n",
      "epoch 16, loss function 5.347176551818848\n",
      "epoch 17, loss function 5.32861328125\n",
      "epoch 18, loss function 5.282236576080322\n",
      "epoch 19, loss function 5.3147382736206055\n",
      "epoch 20, loss function 5.301897048950195\n",
      "epoch 21, loss function 5.218520164489746\n",
      "epoch 22, loss function 5.241352081298828\n",
      "epoch 23, loss function 5.254899978637695\n",
      "epoch 24, loss function 5.260653495788574\n",
      "epoch 25, loss function 5.164997577667236\n",
      "epoch 26, loss function 5.165390968322754\n",
      "epoch 27, loss function 5.18658447265625\n",
      "epoch 28, loss function 5.222107887268066\n",
      "epoch 29, loss function 5.156528949737549\n",
      "epoch 30, loss function 5.154723167419434\n",
      "epoch 31, loss function 5.144397258758545\n",
      "epoch 32, loss function 5.115116119384766\n",
      "epoch 33, loss function 5.105673789978027\n",
      "epoch 34, loss function 5.06512451171875\n",
      "epoch 35, loss function 5.005912780761719\n",
      "epoch 36, loss function 5.011423587799072\n",
      "epoch 37, loss function 5.087841987609863\n",
      "epoch 38, loss function 5.012644290924072\n",
      "epoch 39, loss function 4.987085819244385\n",
      "epoch 40, loss function 4.985487937927246\n",
      "epoch 41, loss function 4.99872350692749\n",
      "epoch 42, loss function 4.94589376449585\n",
      "epoch 43, loss function 4.9594550132751465\n",
      "epoch 44, loss function 4.971157550811768\n",
      "epoch 45, loss function 4.9235100746154785\n",
      "epoch 46, loss function 4.9196577072143555\n",
      "epoch 47, loss function 4.847304821014404\n",
      "epoch 48, loss function 4.858250141143799\n",
      "epoch 49, loss function 4.865957260131836\n",
      "epoch 50, loss function 4.807701110839844\n",
      "epoch 51, loss function 4.789505958557129\n",
      "epoch 52, loss function 4.7988691329956055\n",
      "epoch 53, loss function 4.8436808586120605\n",
      "epoch 54, loss function 4.77519416809082\n",
      "epoch 55, loss function 4.784453392028809\n",
      "epoch 56, loss function 4.788760662078857\n",
      "epoch 57, loss function 4.76649808883667\n",
      "epoch 58, loss function 4.720610618591309\n",
      "epoch 59, loss function 4.724993705749512\n",
      "epoch 60, loss function 4.728169918060303\n",
      "epoch 61, loss function 4.693181037902832\n",
      "epoch 62, loss function 4.704280853271484\n",
      "epoch 63, loss function 4.620258331298828\n",
      "epoch 64, loss function 4.647415637969971\n",
      "epoch 65, loss function 4.600242614746094\n",
      "epoch 66, loss function 4.600832939147949\n",
      "epoch 67, loss function 4.55217981338501\n",
      "epoch 68, loss function 4.582119464874268\n",
      "epoch 69, loss function 4.547588348388672\n",
      "epoch 70, loss function 4.536903381347656\n",
      "epoch 71, loss function 4.517885208129883\n",
      "epoch 72, loss function 4.4808549880981445\n",
      "epoch 73, loss function 4.51961612701416\n",
      "epoch 74, loss function 4.4880571365356445\n",
      "epoch 75, loss function 4.471963882446289\n",
      "epoch 76, loss function 4.414721965789795\n",
      "epoch 77, loss function 4.391188621520996\n",
      "epoch 78, loss function 4.412272930145264\n",
      "epoch 79, loss function 4.454688549041748\n",
      "epoch 80, loss function 4.338525295257568\n",
      "epoch 81, loss function 4.393167018890381\n",
      "epoch 82, loss function 4.346288681030273\n",
      "epoch 83, loss function 4.290875434875488\n",
      "epoch 84, loss function 4.334944248199463\n",
      "epoch 85, loss function 4.273277282714844\n",
      "epoch 86, loss function 4.275828838348389\n",
      "epoch 87, loss function 4.2266411781311035\n",
      "epoch 88, loss function 4.207027435302734\n",
      "epoch 89, loss function 4.254607200622559\n",
      "epoch 90, loss function 4.226108551025391\n",
      "epoch 91, loss function 4.194188117980957\n",
      "epoch 92, loss function 4.155599594116211\n",
      "epoch 93, loss function 4.171862602233887\n",
      "epoch 94, loss function 4.11738395690918\n",
      "epoch 95, loss function 4.099653720855713\n",
      "epoch 96, loss function 4.065557956695557\n",
      "epoch 97, loss function 4.008695602416992\n",
      "epoch 98, loss function 4.082625389099121\n",
      "epoch 99, loss function 4.020247936248779\n",
      "epoch 100, loss function 4.0316619873046875\n",
      "epoch 101, loss function 3.9959323406219482\n",
      "epoch 102, loss function 3.917631149291992\n",
      "epoch 103, loss function 4.010454177856445\n",
      "epoch 104, loss function 3.9020836353302\n",
      "epoch 105, loss function 3.9260170459747314\n",
      "epoch 106, loss function 3.92360520362854\n",
      "epoch 107, loss function 3.9002997875213623\n",
      "epoch 108, loss function 3.843102216720581\n",
      "epoch 109, loss function 3.83404541015625\n",
      "epoch 110, loss function 3.809583902359009\n",
      "epoch 111, loss function 3.805422067642212\n",
      "epoch 112, loss function 3.795677423477173\n",
      "epoch 113, loss function 3.793696880340576\n",
      "epoch 114, loss function 3.733769178390503\n",
      "epoch 115, loss function 3.7945971488952637\n",
      "epoch 116, loss function 3.667780876159668\n",
      "epoch 117, loss function 3.6526477336883545\n",
      "epoch 118, loss function 3.7541072368621826\n",
      "epoch 119, loss function 3.5509660243988037\n",
      "epoch 120, loss function 3.554507255554199\n",
      "epoch 121, loss function 3.604783535003662\n",
      "epoch 122, loss function 3.562959909439087\n",
      "epoch 123, loss function 3.511014461517334\n",
      "epoch 124, loss function 3.571467638015747\n",
      "epoch 125, loss function 3.4755280017852783\n",
      "epoch 126, loss function 3.5576353073120117\n",
      "epoch 127, loss function 3.4706666469573975\n",
      "epoch 128, loss function 3.426008701324463\n",
      "epoch 129, loss function 3.4539966583251953\n",
      "epoch 130, loss function 3.4050261974334717\n",
      "epoch 131, loss function 3.4093759059906006\n",
      "epoch 132, loss function 3.4041354656219482\n",
      "epoch 133, loss function 3.3156535625457764\n",
      "epoch 134, loss function 3.345792293548584\n",
      "epoch 135, loss function 3.193880796432495\n",
      "epoch 136, loss function 3.316779136657715\n",
      "epoch 137, loss function 3.263082504272461\n",
      "epoch 138, loss function 3.195505142211914\n",
      "epoch 139, loss function 3.256004571914673\n",
      "epoch 140, loss function 3.1161370277404785\n",
      "epoch 141, loss function 3.2246720790863037\n",
      "epoch 142, loss function 3.1552510261535645\n",
      "epoch 143, loss function 3.132840156555176\n",
      "epoch 144, loss function 3.0524585247039795\n",
      "epoch 145, loss function 3.0725550651550293\n",
      "epoch 146, loss function 3.0983529090881348\n",
      "epoch 147, loss function 3.022688865661621\n",
      "epoch 148, loss function 2.9591240882873535\n",
      "epoch 149, loss function 2.9686412811279297\n",
      "epoch 150, loss function 2.8977701663970947\n",
      "epoch 151, loss function 2.909658670425415\n",
      "epoch 152, loss function 2.9169862270355225\n",
      "epoch 153, loss function 2.904040813446045\n",
      "epoch 154, loss function 2.850808620452881\n",
      "epoch 155, loss function 2.8293280601501465\n",
      "epoch 156, loss function 2.8335344791412354\n",
      "epoch 157, loss function 2.8623743057250977\n",
      "epoch 158, loss function 2.8260462284088135\n",
      "epoch 159, loss function 2.705148220062256\n",
      "epoch 160, loss function 2.7021801471710205\n",
      "epoch 161, loss function 2.75779128074646\n",
      "epoch 162, loss function 2.7108876705169678\n",
      "epoch 163, loss function 2.5239455699920654\n",
      "epoch 164, loss function 2.6621460914611816\n",
      "epoch 165, loss function 2.6198930740356445\n",
      "epoch 166, loss function 2.5388736724853516\n",
      "epoch 167, loss function 2.4532692432403564\n",
      "epoch 168, loss function 2.532384157180786\n",
      "epoch 169, loss function 2.4908978939056396\n",
      "epoch 170, loss function 2.5098607540130615\n",
      "epoch 171, loss function 2.4723126888275146\n",
      "epoch 172, loss function 2.486177682876587\n",
      "epoch 173, loss function 2.446321964263916\n",
      "epoch 174, loss function 2.4005110263824463\n",
      "epoch 175, loss function 2.3900856971740723\n",
      "epoch 176, loss function 2.3517327308654785\n",
      "epoch 177, loss function 2.2386369705200195\n",
      "epoch 178, loss function 2.3226559162139893\n",
      "epoch 179, loss function 2.1827847957611084\n",
      "epoch 180, loss function 2.2728848457336426\n",
      "epoch 181, loss function 2.282524347305298\n",
      "epoch 182, loss function 2.153406858444214\n",
      "epoch 183, loss function 2.065953493118286\n",
      "epoch 184, loss function 2.1638054847717285\n",
      "epoch 185, loss function 2.0331404209136963\n",
      "epoch 186, loss function 2.141817331314087\n",
      "epoch 187, loss function 2.111314058303833\n",
      "epoch 188, loss function 2.006232738494873\n",
      "epoch 189, loss function 2.051602363586426\n",
      "epoch 190, loss function 1.9598087072372437\n",
      "epoch 191, loss function 1.9485682249069214\n",
      "epoch 192, loss function 1.9248124361038208\n",
      "epoch 193, loss function 1.9629629850387573\n",
      "epoch 194, loss function 1.9387197494506836\n",
      "epoch 195, loss function 1.9299826622009277\n",
      "epoch 196, loss function 1.8505479097366333\n",
      "epoch 197, loss function 1.79896879196167\n",
      "epoch 198, loss function 1.8688417673110962\n",
      "epoch 199, loss function 1.8545762300491333\n",
      "epoch 200, loss function 1.7579832077026367\n",
      "epoch 201, loss function 1.8609791994094849\n",
      "epoch 202, loss function 1.852522850036621\n",
      "epoch 203, loss function 1.7601627111434937\n",
      "epoch 204, loss function 1.774877905845642\n",
      "epoch 205, loss function 1.7072086334228516\n",
      "epoch 206, loss function 1.7160910367965698\n",
      "epoch 207, loss function 1.620863437652588\n",
      "epoch 208, loss function 1.6598594188690186\n",
      "epoch 209, loss function 1.7197104692459106\n",
      "epoch 210, loss function 1.692264199256897\n",
      "epoch 211, loss function 1.6829416751861572\n",
      "epoch 212, loss function 1.7712675333023071\n",
      "epoch 213, loss function 1.7087112665176392\n",
      "epoch 214, loss function 1.642805576324463\n",
      "epoch 215, loss function 1.5742619037628174\n",
      "epoch 216, loss function 1.6580835580825806\n",
      "epoch 217, loss function 1.6602656841278076\n",
      "epoch 218, loss function 1.5066969394683838\n",
      "epoch 219, loss function 1.54248046875\n",
      "epoch 220, loss function 1.5700480937957764\n",
      "epoch 221, loss function 1.4303785562515259\n",
      "epoch 222, loss function 1.5597878694534302\n",
      "epoch 223, loss function 1.545684814453125\n",
      "epoch 224, loss function 1.5231823921203613\n",
      "epoch 225, loss function 1.5231833457946777\n",
      "epoch 226, loss function 1.5329475402832031\n",
      "epoch 227, loss function 1.4880753755569458\n",
      "epoch 228, loss function 1.4827427864074707\n",
      "epoch 229, loss function 1.5664256811141968\n",
      "epoch 230, loss function 1.5323714017868042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 231, loss function 1.463745355606079\n",
      "epoch 232, loss function 1.4348877668380737\n",
      "epoch 233, loss function 1.403346061706543\n",
      "epoch 234, loss function 1.3285441398620605\n",
      "epoch 235, loss function 1.4814709424972534\n",
      "epoch 236, loss function 1.4649972915649414\n",
      "epoch 237, loss function 1.42586088180542\n",
      "epoch 238, loss function 1.4068478345870972\n",
      "epoch 239, loss function 1.3931119441986084\n",
      "epoch 240, loss function 1.406333565711975\n",
      "epoch 241, loss function 1.3971227407455444\n",
      "epoch 242, loss function 1.3322912454605103\n",
      "epoch 243, loss function 1.3820196390151978\n",
      "epoch 244, loss function 1.3049616813659668\n",
      "epoch 245, loss function 1.2024964094161987\n",
      "epoch 246, loss function 1.3229708671569824\n",
      "epoch 247, loss function 1.2551497220993042\n",
      "epoch 248, loss function 1.2654451131820679\n",
      "epoch 249, loss function 1.2572749853134155\n",
      "epoch 250, loss function 1.25473153591156\n",
      "epoch 251, loss function 1.1989994049072266\n",
      "epoch 252, loss function 1.2734804153442383\n",
      "epoch 253, loss function 1.3722718954086304\n",
      "epoch 254, loss function 1.193299412727356\n",
      "epoch 255, loss function 1.259993314743042\n",
      "epoch 256, loss function 1.3321236371994019\n",
      "epoch 257, loss function 1.2773874998092651\n",
      "epoch 258, loss function 1.3399760723114014\n",
      "epoch 259, loss function 1.2690225839614868\n",
      "epoch 260, loss function 1.3052548170089722\n",
      "epoch 261, loss function 1.3881194591522217\n",
      "epoch 262, loss function 1.24856698513031\n",
      "epoch 263, loss function 1.3796031475067139\n",
      "epoch 264, loss function 1.3315975666046143\n",
      "epoch 265, loss function 1.2690482139587402\n",
      "epoch 266, loss function 1.2740710973739624\n",
      "epoch 267, loss function 1.240207314491272\n",
      "epoch 268, loss function 1.304298996925354\n",
      "epoch 269, loss function 1.241003155708313\n",
      "epoch 270, loss function 1.17611825466156\n",
      "epoch 271, loss function 1.2236343622207642\n",
      "epoch 272, loss function 1.3020966053009033\n",
      "epoch 273, loss function 1.287151575088501\n",
      "epoch 274, loss function 1.3246980905532837\n",
      "epoch 275, loss function 1.2058316469192505\n",
      "epoch 276, loss function 1.2426725625991821\n",
      "epoch 277, loss function 1.3132798671722412\n",
      "epoch 278, loss function 1.2866795063018799\n",
      "epoch 279, loss function 1.1826584339141846\n",
      "epoch 280, loss function 1.2362613677978516\n",
      "epoch 281, loss function 1.2153260707855225\n",
      "epoch 282, loss function 1.1059846878051758\n",
      "epoch 283, loss function 1.1476386785507202\n",
      "epoch 284, loss function 1.182854413986206\n",
      "epoch 285, loss function 1.1844290494918823\n",
      "epoch 286, loss function 1.3412100076675415\n",
      "epoch 287, loss function 1.2798042297363281\n",
      "epoch 288, loss function 1.2683218717575073\n",
      "epoch 289, loss function 1.2240477800369263\n",
      "epoch 290, loss function 1.1406041383743286\n",
      "epoch 291, loss function 1.2543917894363403\n",
      "epoch 292, loss function 1.2171708345413208\n",
      "epoch 293, loss function 1.2931183576583862\n",
      "epoch 294, loss function 1.2910887002944946\n",
      "epoch 295, loss function 1.1878806352615356\n",
      "epoch 296, loss function 1.1817471981048584\n",
      "epoch 297, loss function 1.28288733959198\n",
      "epoch 298, loss function 1.2229782342910767\n",
      "epoch 299, loss function 1.2001961469650269\n",
      "epoch 300, loss function 1.3040776252746582\n",
      "epoch 301, loss function 1.2936179637908936\n",
      "epoch 302, loss function 1.2129638195037842\n",
      "epoch 303, loss function 1.2508195638656616\n",
      "epoch 304, loss function 1.3058308362960815\n",
      "epoch 305, loss function 1.2660894393920898\n",
      "epoch 306, loss function 1.1958510875701904\n",
      "epoch 307, loss function 1.2158172130584717\n",
      "epoch 308, loss function 1.2299060821533203\n",
      "epoch 309, loss function 1.2468994855880737\n",
      "epoch 310, loss function 1.3127784729003906\n",
      "epoch 311, loss function 1.2492698431015015\n",
      "epoch 312, loss function 1.2749171257019043\n",
      "epoch 313, loss function 1.2542086839675903\n",
      "epoch 314, loss function 1.2108277082443237\n",
      "epoch 315, loss function 1.2827694416046143\n",
      "epoch 316, loss function 1.2351139783859253\n",
      "epoch 317, loss function 1.2344855070114136\n",
      "epoch 318, loss function 1.0517733097076416\n",
      "epoch 319, loss function 1.198951244354248\n",
      "epoch 320, loss function 1.3049238920211792\n",
      "epoch 321, loss function 1.2194197177886963\n",
      "epoch 322, loss function 1.22921884059906\n",
      "epoch 323, loss function 1.260765552520752\n",
      "epoch 324, loss function 1.3288449048995972\n",
      "epoch 325, loss function 1.2370860576629639\n",
      "epoch 326, loss function 1.1881532669067383\n",
      "epoch 327, loss function 1.193389892578125\n",
      "epoch 328, loss function 1.1692016124725342\n",
      "epoch 329, loss function 1.1978986263275146\n",
      "epoch 330, loss function 1.3192251920700073\n",
      "epoch 331, loss function 1.2055914402008057\n",
      "epoch 332, loss function 1.2258892059326172\n",
      "epoch 333, loss function 1.189004898071289\n",
      "epoch 334, loss function 1.3445062637329102\n",
      "epoch 335, loss function 1.2013072967529297\n",
      "epoch 336, loss function 1.3203060626983643\n",
      "epoch 337, loss function 1.3220287561416626\n",
      "epoch 338, loss function 1.1577191352844238\n",
      "epoch 339, loss function 1.1365711688995361\n",
      "epoch 340, loss function 1.1645846366882324\n",
      "epoch 341, loss function 1.187223196029663\n",
      "epoch 342, loss function 1.1409196853637695\n",
      "epoch 343, loss function 1.2375750541687012\n",
      "epoch 344, loss function 1.1201239824295044\n",
      "epoch 345, loss function 1.266757845878601\n",
      "epoch 346, loss function 1.1779789924621582\n",
      "epoch 347, loss function 1.2102398872375488\n",
      "epoch 348, loss function 1.4475069046020508\n",
      "epoch 349, loss function 1.1681458950042725\n",
      "epoch 350, loss function 1.2848033905029297\n",
      "epoch 351, loss function 1.1509056091308594\n",
      "epoch 352, loss function 1.2356314659118652\n",
      "epoch 353, loss function 1.1630640029907227\n",
      "epoch 354, loss function 1.2272744178771973\n",
      "epoch 355, loss function 1.1456800699234009\n",
      "epoch 356, loss function 1.1502387523651123\n",
      "epoch 357, loss function 1.150450587272644\n",
      "epoch 358, loss function 1.2507314682006836\n",
      "epoch 359, loss function 1.2470625638961792\n",
      "epoch 360, loss function 1.2178425788879395\n",
      "epoch 361, loss function 1.1480445861816406\n",
      "epoch 362, loss function 1.2030309438705444\n",
      "epoch 363, loss function 1.1943577527999878\n",
      "epoch 364, loss function 1.1947412490844727\n",
      "epoch 365, loss function 1.2212029695510864\n",
      "epoch 366, loss function 1.2507810592651367\n",
      "epoch 367, loss function 1.209966778755188\n",
      "epoch 368, loss function 1.2231451272964478\n",
      "epoch 369, loss function 1.2185053825378418\n",
      "epoch 370, loss function 1.2531607151031494\n",
      "epoch 371, loss function 1.2751632928848267\n",
      "epoch 372, loss function 1.1537532806396484\n",
      "epoch 373, loss function 1.2055822610855103\n",
      "epoch 374, loss function 1.1778427362442017\n",
      "epoch 375, loss function 1.1928521394729614\n",
      "epoch 376, loss function 1.2430907487869263\n",
      "epoch 377, loss function 1.1732019186019897\n",
      "epoch 378, loss function 1.2657973766326904\n",
      "epoch 379, loss function 1.111411452293396\n",
      "epoch 380, loss function 1.0963040590286255\n",
      "epoch 381, loss function 1.2184388637542725\n",
      "epoch 382, loss function 1.121286153793335\n",
      "epoch 383, loss function 1.2889598608016968\n",
      "epoch 384, loss function 1.2196866273880005\n",
      "epoch 385, loss function 1.2078535556793213\n",
      "epoch 386, loss function 1.2788559198379517\n",
      "epoch 387, loss function 1.1801475286483765\n",
      "epoch 388, loss function 1.1150078773498535\n",
      "epoch 389, loss function 1.2268877029418945\n",
      "epoch 390, loss function 1.2117080688476562\n",
      "epoch 391, loss function 1.1824884414672852\n",
      "epoch 392, loss function 1.1990058422088623\n",
      "epoch 393, loss function 1.1966969966888428\n",
      "epoch 394, loss function 1.2018300294876099\n",
      "epoch 395, loss function 1.1338461637496948\n",
      "epoch 396, loss function 1.2090866565704346\n",
      "epoch 397, loss function 1.1907145977020264\n",
      "epoch 398, loss function 1.25844144821167\n",
      "epoch 399, loss function 1.2968770265579224\n",
      "epoch 400, loss function 1.149976134300232\n",
      "epoch 401, loss function 1.15058171749115\n",
      "epoch 402, loss function 1.2298064231872559\n",
      "epoch 403, loss function 1.2002208232879639\n",
      "epoch 404, loss function 1.2186449766159058\n",
      "epoch 405, loss function 1.1704812049865723\n",
      "epoch 406, loss function 1.2100064754486084\n",
      "epoch 407, loss function 1.1130141019821167\n",
      "epoch 408, loss function 1.2287172079086304\n",
      "epoch 409, loss function 1.2271260023117065\n",
      "epoch 410, loss function 1.1952953338623047\n",
      "epoch 411, loss function 1.2583881616592407\n",
      "epoch 412, loss function 1.1038360595703125\n",
      "epoch 413, loss function 1.2120506763458252\n",
      "epoch 414, loss function 1.2911828756332397\n",
      "epoch 415, loss function 1.0739734172821045\n",
      "epoch 416, loss function 1.1588878631591797\n",
      "epoch 417, loss function 1.1661332845687866\n",
      "epoch 418, loss function 1.133554458618164\n",
      "epoch 419, loss function 1.1305917501449585\n",
      "epoch 420, loss function 1.093694806098938\n",
      "epoch 421, loss function 1.148740530014038\n",
      "epoch 422, loss function 1.2880109548568726\n",
      "epoch 423, loss function 1.145401954650879\n",
      "epoch 424, loss function 1.2433509826660156\n",
      "epoch 425, loss function 1.124131441116333\n",
      "epoch 426, loss function 1.311599850654602\n",
      "epoch 427, loss function 1.123715877532959\n",
      "epoch 428, loss function 1.1789804697036743\n",
      "epoch 429, loss function 1.0447275638580322\n",
      "epoch 430, loss function 1.3627960681915283\n",
      "epoch 431, loss function 1.1606310606002808\n",
      "epoch 432, loss function 1.2038682699203491\n",
      "epoch 433, loss function 1.1365249156951904\n",
      "epoch 434, loss function 1.2521953582763672\n",
      "epoch 435, loss function 1.1991546154022217\n",
      "epoch 436, loss function 1.251918911933899\n",
      "epoch 437, loss function 1.2158007621765137\n",
      "epoch 438, loss function 1.0781314373016357\n",
      "epoch 439, loss function 1.2100995779037476\n",
      "epoch 440, loss function 1.0894172191619873\n",
      "epoch 441, loss function 1.2153563499450684\n",
      "epoch 442, loss function 1.310001015663147\n",
      "epoch 443, loss function 1.1779532432556152\n",
      "epoch 444, loss function 1.0665943622589111\n",
      "epoch 445, loss function 1.1189683675765991\n",
      "epoch 446, loss function 1.12855863571167\n",
      "epoch 447, loss function 1.0910248756408691\n",
      "epoch 448, loss function 1.2468839883804321\n",
      "epoch 449, loss function 1.098912239074707\n",
      "epoch 450, loss function 1.1586134433746338\n",
      "epoch 451, loss function 1.2706259489059448\n",
      "epoch 452, loss function 1.238059163093567\n",
      "epoch 453, loss function 1.1242479085922241\n",
      "epoch 454, loss function 1.1540007591247559\n",
      "epoch 455, loss function 1.1713122129440308\n",
      "epoch 456, loss function 1.1352930068969727\n",
      "epoch 457, loss function 1.0735459327697754\n",
      "epoch 458, loss function 1.1817294359207153\n",
      "epoch 459, loss function 1.1160011291503906\n",
      "epoch 460, loss function 1.2051759958267212\n",
      "epoch 461, loss function 1.1794631481170654\n",
      "epoch 462, loss function 1.1298493146896362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 463, loss function 1.1014989614486694\n",
      "epoch 464, loss function 1.176023006439209\n",
      "epoch 465, loss function 1.1591365337371826\n",
      "epoch 466, loss function 1.189505696296692\n",
      "epoch 467, loss function 1.2236263751983643\n",
      "epoch 468, loss function 1.154327630996704\n",
      "epoch 469, loss function 1.1236283779144287\n",
      "epoch 470, loss function 1.239477515220642\n",
      "epoch 471, loss function 1.1193597316741943\n",
      "epoch 472, loss function 1.2322899103164673\n",
      "epoch 473, loss function 1.0615947246551514\n",
      "epoch 474, loss function 1.1825408935546875\n",
      "epoch 475, loss function 1.250105619430542\n",
      "epoch 476, loss function 1.1990346908569336\n",
      "epoch 477, loss function 1.127458930015564\n",
      "epoch 478, loss function 1.2480144500732422\n",
      "epoch 479, loss function 1.1176600456237793\n",
      "epoch 480, loss function 1.0850247144699097\n",
      "epoch 481, loss function 1.2557475566864014\n",
      "epoch 482, loss function 1.1320182085037231\n",
      "epoch 483, loss function 1.255759358406067\n",
      "epoch 484, loss function 1.1723523139953613\n",
      "epoch 485, loss function 1.203905701637268\n",
      "epoch 486, loss function 1.079412817955017\n",
      "epoch 487, loss function 1.204088568687439\n",
      "epoch 488, loss function 1.109346628189087\n",
      "epoch 489, loss function 1.1173198223114014\n",
      "epoch 490, loss function 1.1297235488891602\n",
      "epoch 491, loss function 1.1405067443847656\n",
      "epoch 492, loss function 1.2089898586273193\n",
      "epoch 493, loss function 1.1988550424575806\n",
      "epoch 494, loss function 1.171727180480957\n",
      "epoch 495, loss function 1.168352723121643\n",
      "epoch 496, loss function 1.110530138015747\n",
      "epoch 497, loss function 1.1879878044128418\n",
      "epoch 498, loss function 1.158347725868225\n",
      "epoch 499, loss function 1.075587272644043\n",
      "epoch 500, loss function 1.160417079925537\n",
      "epoch 501, loss function 1.0895682573318481\n",
      "epoch 502, loss function 1.1894187927246094\n",
      "epoch 503, loss function 1.150073528289795\n",
      "epoch 504, loss function 1.2130210399627686\n",
      "epoch 505, loss function 1.1996848583221436\n",
      "epoch 506, loss function 1.2123675346374512\n",
      "epoch 507, loss function 1.134605050086975\n",
      "epoch 508, loss function 1.209545373916626\n",
      "epoch 509, loss function 1.1238503456115723\n",
      "epoch 510, loss function 1.048247218132019\n",
      "epoch 511, loss function 1.2075446844100952\n",
      "epoch 512, loss function 1.1371347904205322\n",
      "epoch 513, loss function 1.1763834953308105\n",
      "epoch 514, loss function 1.0757758617401123\n",
      "epoch 515, loss function 1.3394893407821655\n",
      "epoch 516, loss function 1.0454515218734741\n",
      "epoch 517, loss function 1.1521836519241333\n",
      "epoch 518, loss function 1.2886807918548584\n",
      "epoch 519, loss function 1.2094086408615112\n",
      "epoch 520, loss function 1.109049677848816\n",
      "epoch 521, loss function 1.1819289922714233\n",
      "epoch 522, loss function 1.0214781761169434\n",
      "epoch 523, loss function 1.157410740852356\n",
      "epoch 524, loss function 1.2384523153305054\n",
      "epoch 525, loss function 1.1238538026809692\n",
      "epoch 526, loss function 1.116440773010254\n",
      "epoch 527, loss function 1.2027291059494019\n",
      "epoch 528, loss function 1.111157774925232\n",
      "epoch 529, loss function 1.321368932723999\n",
      "epoch 530, loss function 1.1028262376785278\n",
      "epoch 531, loss function 1.1275615692138672\n",
      "epoch 532, loss function 1.0796388387680054\n",
      "epoch 533, loss function 1.1720497608184814\n",
      "epoch 534, loss function 1.0686098337173462\n",
      "epoch 535, loss function 1.1342989206314087\n",
      "epoch 536, loss function 1.126115083694458\n",
      "epoch 537, loss function 1.1149792671203613\n",
      "epoch 538, loss function 1.169049620628357\n",
      "epoch 539, loss function 1.216975450515747\n",
      "epoch 540, loss function 1.2144330739974976\n",
      "epoch 541, loss function 1.1943484544754028\n",
      "epoch 542, loss function 1.0182735919952393\n",
      "epoch 543, loss function 1.157621145248413\n",
      "epoch 544, loss function 1.1779910326004028\n",
      "epoch 545, loss function 1.2101192474365234\n",
      "epoch 546, loss function 1.1530636548995972\n",
      "epoch 547, loss function 1.1314771175384521\n",
      "epoch 548, loss function 1.1223266124725342\n",
      "epoch 549, loss function 1.0799329280853271\n",
      "epoch 550, loss function 1.1505404710769653\n",
      "epoch 551, loss function 1.187461018562317\n",
      "epoch 552, loss function 1.0976669788360596\n",
      "epoch 553, loss function 1.158491849899292\n",
      "epoch 554, loss function 1.1461831331253052\n",
      "epoch 555, loss function 1.1675440073013306\n",
      "epoch 556, loss function 1.1890690326690674\n",
      "epoch 557, loss function 1.0644623041152954\n",
      "epoch 558, loss function 1.1432512998580933\n",
      "epoch 559, loss function 1.07184636592865\n",
      "epoch 560, loss function 1.2084782123565674\n",
      "epoch 561, loss function 1.1048954725265503\n",
      "epoch 562, loss function 1.2120281457901\n",
      "epoch 563, loss function 1.1738481521606445\n",
      "epoch 564, loss function 1.229273796081543\n",
      "epoch 565, loss function 1.1270344257354736\n",
      "epoch 566, loss function 1.1267091035842896\n",
      "epoch 567, loss function 1.1163498163223267\n",
      "epoch 568, loss function 1.1701180934906006\n",
      "epoch 569, loss function 1.1498323678970337\n",
      "epoch 570, loss function 1.215451955795288\n",
      "epoch 571, loss function 1.2528156042099\n",
      "epoch 572, loss function 1.1021472215652466\n",
      "epoch 573, loss function 1.2280151844024658\n",
      "epoch 574, loss function 1.1200127601623535\n",
      "epoch 575, loss function 1.1251821517944336\n",
      "epoch 576, loss function 1.14299738407135\n",
      "epoch 577, loss function 1.1227450370788574\n",
      "epoch 578, loss function 1.0159659385681152\n",
      "epoch 579, loss function 1.104719877243042\n",
      "epoch 580, loss function 1.0820446014404297\n",
      "epoch 581, loss function 1.1992881298065186\n",
      "epoch 582, loss function 1.0930253267288208\n",
      "epoch 583, loss function 0.9668715596199036\n",
      "epoch 584, loss function 1.0519834756851196\n",
      "epoch 585, loss function 1.1905763149261475\n",
      "epoch 586, loss function 1.1422834396362305\n",
      "epoch 587, loss function 1.2003077268600464\n",
      "epoch 588, loss function 1.114651083946228\n",
      "epoch 589, loss function 1.152642011642456\n",
      "epoch 590, loss function 1.1018043756484985\n",
      "epoch 591, loss function 1.1999849081039429\n",
      "epoch 592, loss function 1.1120810508728027\n",
      "epoch 593, loss function 1.172800064086914\n",
      "epoch 594, loss function 1.1751599311828613\n",
      "epoch 595, loss function 1.0378682613372803\n",
      "epoch 596, loss function 1.1203826665878296\n",
      "epoch 597, loss function 1.171895980834961\n",
      "epoch 598, loss function 1.1505752801895142\n",
      "epoch 599, loss function 1.114781379699707\n",
      "epoch 600, loss function 1.192736029624939\n",
      "epoch 601, loss function 1.154990553855896\n",
      "epoch 602, loss function 1.1186614036560059\n",
      "epoch 603, loss function 1.1436439752578735\n",
      "epoch 604, loss function 1.1241767406463623\n",
      "epoch 605, loss function 1.1309415102005005\n",
      "epoch 606, loss function 1.021224021911621\n",
      "epoch 607, loss function 1.0653941631317139\n",
      "epoch 608, loss function 1.152456283569336\n",
      "epoch 609, loss function 1.0602601766586304\n",
      "epoch 610, loss function 1.1411131620407104\n",
      "epoch 611, loss function 1.1128735542297363\n",
      "epoch 612, loss function 1.1662265062332153\n",
      "epoch 613, loss function 1.1282562017440796\n",
      "epoch 614, loss function 1.0938639640808105\n",
      "epoch 615, loss function 1.1918803453445435\n",
      "epoch 616, loss function 1.0302319526672363\n",
      "epoch 617, loss function 1.1629294157028198\n",
      "epoch 618, loss function 1.1635807752609253\n",
      "epoch 619, loss function 1.0734318494796753\n",
      "epoch 620, loss function 1.2161201238632202\n",
      "epoch 621, loss function 1.109325647354126\n",
      "epoch 622, loss function 1.1770861148834229\n",
      "epoch 623, loss function 1.094840407371521\n",
      "epoch 624, loss function 1.0286895036697388\n",
      "epoch 625, loss function 1.1021453142166138\n",
      "epoch 626, loss function 1.1790077686309814\n",
      "epoch 627, loss function 1.0971266031265259\n",
      "epoch 628, loss function 0.9287188649177551\n",
      "epoch 629, loss function 1.095176339149475\n",
      "epoch 630, loss function 1.0004738569259644\n",
      "epoch 631, loss function 1.0943233966827393\n",
      "epoch 632, loss function 1.0611770153045654\n",
      "epoch 633, loss function 1.1033380031585693\n",
      "epoch 634, loss function 1.1772894859313965\n",
      "epoch 635, loss function 1.1322977542877197\n",
      "epoch 636, loss function 1.151014804840088\n",
      "epoch 637, loss function 1.1673312187194824\n",
      "epoch 638, loss function 1.151724100112915\n",
      "epoch 639, loss function 1.0585016012191772\n",
      "epoch 640, loss function 1.1706002950668335\n",
      "epoch 641, loss function 1.1681872606277466\n",
      "epoch 642, loss function 1.1434346437454224\n",
      "epoch 643, loss function 1.168414831161499\n",
      "epoch 644, loss function 1.1198153495788574\n",
      "epoch 645, loss function 1.0932350158691406\n",
      "epoch 646, loss function 1.221595287322998\n",
      "epoch 647, loss function 1.1663048267364502\n",
      "epoch 648, loss function 1.1406739950180054\n",
      "epoch 649, loss function 1.0661859512329102\n",
      "epoch 650, loss function 1.157772421836853\n",
      "epoch 651, loss function 1.1206698417663574\n",
      "epoch 652, loss function 1.0919783115386963\n",
      "epoch 653, loss function 1.082879900932312\n",
      "epoch 654, loss function 1.0541930198669434\n",
      "epoch 655, loss function 1.0329819917678833\n",
      "epoch 656, loss function 1.1441779136657715\n",
      "epoch 657, loss function 1.1266427040100098\n",
      "epoch 658, loss function 1.0901051759719849\n",
      "epoch 659, loss function 1.1267247200012207\n",
      "epoch 660, loss function 1.0574030876159668\n",
      "epoch 661, loss function 1.086295485496521\n",
      "epoch 662, loss function 1.0868393182754517\n",
      "epoch 663, loss function 1.0731486082077026\n",
      "epoch 664, loss function 1.0870469808578491\n",
      "epoch 665, loss function 1.0822149515151978\n",
      "epoch 666, loss function 1.083011269569397\n",
      "epoch 667, loss function 1.0718038082122803\n",
      "epoch 668, loss function 1.1756179332733154\n",
      "epoch 669, loss function 1.1359270811080933\n",
      "epoch 670, loss function 1.2496687173843384\n",
      "epoch 671, loss function 1.1220628023147583\n",
      "epoch 672, loss function 1.0821040868759155\n",
      "epoch 673, loss function 1.05899178981781\n",
      "epoch 674, loss function 1.1581816673278809\n",
      "epoch 675, loss function 1.0261253118515015\n",
      "epoch 676, loss function 1.1186233758926392\n",
      "epoch 677, loss function 1.1547404527664185\n",
      "epoch 678, loss function 1.1476622819900513\n",
      "epoch 679, loss function 1.082311749458313\n",
      "epoch 680, loss function 1.1340833902359009\n",
      "epoch 681, loss function 1.1542845964431763\n",
      "epoch 682, loss function 1.124545693397522\n",
      "epoch 683, loss function 1.0482784509658813\n",
      "epoch 684, loss function 1.129386305809021\n",
      "epoch 685, loss function 1.1602991819381714\n",
      "epoch 686, loss function 1.155917763710022\n",
      "epoch 687, loss function 1.1954758167266846\n",
      "epoch 688, loss function 1.0296474695205688\n",
      "epoch 689, loss function 1.0509486198425293\n",
      "epoch 690, loss function 1.1027686595916748\n",
      "epoch 691, loss function 1.024153232574463\n",
      "epoch 692, loss function 1.2304202318191528\n",
      "epoch 693, loss function 1.1190953254699707\n",
      "epoch 694, loss function 1.0630170106887817\n",
      "epoch 695, loss function 0.9912737607955933\n",
      "epoch 696, loss function 1.0803828239440918\n",
      "epoch 697, loss function 1.0354738235473633\n",
      "epoch 698, loss function 1.155364751815796\n",
      "epoch 699, loss function 1.0942665338516235\n",
      "epoch 700, loss function 1.1347119808197021\n",
      "epoch 701, loss function 1.0223650932312012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 702, loss function 1.0085690021514893\n",
      "epoch 703, loss function 1.0572457313537598\n",
      "epoch 704, loss function 1.1227542161941528\n",
      "epoch 705, loss function 1.1052517890930176\n",
      "epoch 706, loss function 1.1786773204803467\n",
      "epoch 707, loss function 1.1275511980056763\n",
      "epoch 708, loss function 1.106724500656128\n",
      "epoch 709, loss function 1.0855165719985962\n",
      "epoch 710, loss function 1.1221524477005005\n",
      "epoch 711, loss function 1.0249066352844238\n",
      "epoch 712, loss function 1.056662678718567\n",
      "epoch 713, loss function 1.148978352546692\n",
      "epoch 714, loss function 1.0630288124084473\n",
      "epoch 715, loss function 1.0571041107177734\n",
      "epoch 716, loss function 1.1363708972930908\n",
      "epoch 717, loss function 1.1474361419677734\n",
      "epoch 718, loss function 1.0011937618255615\n",
      "epoch 719, loss function 1.1658605337142944\n",
      "epoch 720, loss function 1.1641089916229248\n",
      "epoch 721, loss function 1.1608881950378418\n",
      "epoch 722, loss function 1.17071533203125\n",
      "epoch 723, loss function 1.0576753616333008\n",
      "epoch 724, loss function 1.1604595184326172\n",
      "epoch 725, loss function 1.1189734935760498\n",
      "epoch 726, loss function 1.100377082824707\n",
      "epoch 727, loss function 1.0386950969696045\n",
      "epoch 728, loss function 1.1227433681488037\n",
      "epoch 729, loss function 1.179307222366333\n",
      "epoch 730, loss function 1.1117041110992432\n",
      "epoch 731, loss function 1.145496129989624\n",
      "epoch 732, loss function 1.159559726715088\n",
      "epoch 733, loss function 1.0775797367095947\n",
      "epoch 734, loss function 1.0204505920410156\n",
      "epoch 735, loss function 1.171743631362915\n",
      "epoch 736, loss function 1.047607183456421\n",
      "epoch 737, loss function 1.0520508289337158\n",
      "epoch 738, loss function 1.0138474702835083\n",
      "epoch 739, loss function 1.0645196437835693\n",
      "epoch 740, loss function 1.1512919664382935\n",
      "epoch 741, loss function 1.086116909980774\n",
      "epoch 742, loss function 1.0871912240982056\n",
      "epoch 743, loss function 1.041579008102417\n",
      "epoch 744, loss function 1.0872620344161987\n",
      "epoch 745, loss function 1.1418036222457886\n",
      "epoch 746, loss function 1.1248012781143188\n",
      "epoch 747, loss function 1.056645154953003\n",
      "epoch 748, loss function 1.1042439937591553\n",
      "epoch 749, loss function 1.1803725957870483\n",
      "epoch 750, loss function 1.0974332094192505\n",
      "epoch 751, loss function 1.0876950025558472\n",
      "epoch 752, loss function 1.1209436655044556\n",
      "epoch 753, loss function 1.0603282451629639\n",
      "epoch 754, loss function 1.0357608795166016\n",
      "epoch 755, loss function 1.0740141868591309\n",
      "epoch 756, loss function 1.1028410196304321\n",
      "epoch 757, loss function 1.1324360370635986\n",
      "epoch 758, loss function 1.0931364297866821\n",
      "epoch 759, loss function 1.1004600524902344\n",
      "epoch 760, loss function 1.097817063331604\n",
      "epoch 761, loss function 1.121359944343567\n",
      "epoch 762, loss function 1.1274598836898804\n",
      "epoch 763, loss function 1.160162091255188\n",
      "epoch 764, loss function 1.0387815237045288\n",
      "epoch 765, loss function 1.1502526998519897\n",
      "epoch 766, loss function 1.142542839050293\n",
      "epoch 767, loss function 1.1341980695724487\n",
      "epoch 768, loss function 1.1696547269821167\n",
      "epoch 769, loss function 1.091675877571106\n",
      "epoch 770, loss function 1.1082820892333984\n",
      "epoch 771, loss function 1.054587721824646\n",
      "epoch 772, loss function 1.0613160133361816\n",
      "epoch 773, loss function 1.039859652519226\n",
      "epoch 774, loss function 1.0804224014282227\n",
      "epoch 775, loss function 1.0375926494598389\n",
      "epoch 776, loss function 1.070850133895874\n",
      "epoch 777, loss function 1.0871587991714478\n",
      "epoch 778, loss function 1.1369508504867554\n",
      "epoch 779, loss function 1.14370858669281\n",
      "epoch 780, loss function 1.0644792318344116\n",
      "epoch 781, loss function 1.1493511199951172\n",
      "epoch 782, loss function 1.085964322090149\n",
      "epoch 783, loss function 1.0053415298461914\n",
      "epoch 784, loss function 1.0922811031341553\n",
      "epoch 785, loss function 1.056572675704956\n",
      "epoch 786, loss function 1.138698935508728\n",
      "epoch 787, loss function 1.05097234249115\n",
      "epoch 788, loss function 1.0116114616394043\n",
      "epoch 789, loss function 1.0974266529083252\n",
      "epoch 790, loss function 1.070657730102539\n",
      "epoch 791, loss function 1.162624716758728\n",
      "epoch 792, loss function 1.0780295133590698\n",
      "epoch 793, loss function 1.0313663482666016\n",
      "epoch 794, loss function 1.146328091621399\n",
      "epoch 795, loss function 1.0197038650512695\n",
      "epoch 796, loss function 1.046259880065918\n",
      "epoch 797, loss function 1.012917160987854\n",
      "epoch 798, loss function 1.1062664985656738\n",
      "epoch 799, loss function 1.0962567329406738\n",
      "epoch 800, loss function 1.1464308500289917\n",
      "epoch 801, loss function 1.1342676877975464\n",
      "epoch 802, loss function 1.2056939601898193\n",
      "epoch 803, loss function 0.9783855676651001\n",
      "epoch 804, loss function 1.0899161100387573\n",
      "epoch 805, loss function 1.0806180238723755\n",
      "epoch 806, loss function 1.1029685735702515\n",
      "epoch 807, loss function 1.1222219467163086\n",
      "epoch 808, loss function 1.1124449968338013\n",
      "epoch 809, loss function 0.9916688799858093\n",
      "epoch 810, loss function 1.2449617385864258\n",
      "epoch 811, loss function 1.1838353872299194\n",
      "epoch 812, loss function 0.9599972367286682\n",
      "epoch 813, loss function 1.0750830173492432\n",
      "epoch 814, loss function 0.9814837574958801\n",
      "epoch 815, loss function 1.1491607427597046\n",
      "epoch 816, loss function 1.0631669759750366\n",
      "epoch 817, loss function 1.105635404586792\n",
      "epoch 818, loss function 1.0827559232711792\n",
      "epoch 819, loss function 1.0242319107055664\n",
      "epoch 820, loss function 1.1490230560302734\n",
      "epoch 821, loss function 1.0073171854019165\n",
      "epoch 822, loss function 1.113080620765686\n",
      "epoch 823, loss function 1.0846582651138306\n",
      "epoch 824, loss function 1.150560975074768\n",
      "epoch 825, loss function 1.1116344928741455\n",
      "epoch 826, loss function 1.0702725648880005\n",
      "epoch 827, loss function 1.1016913652420044\n",
      "epoch 828, loss function 1.0993019342422485\n",
      "epoch 829, loss function 0.9969716668128967\n",
      "epoch 830, loss function 1.0772874355316162\n",
      "epoch 831, loss function 1.0352764129638672\n",
      "epoch 832, loss function 0.9941570162773132\n",
      "epoch 833, loss function 1.0871260166168213\n",
      "epoch 834, loss function 1.0020242929458618\n",
      "epoch 835, loss function 1.0656007528305054\n",
      "epoch 836, loss function 1.1110584735870361\n",
      "epoch 837, loss function 1.0718809366226196\n",
      "epoch 838, loss function 1.1501519680023193\n",
      "epoch 839, loss function 1.0374807119369507\n",
      "epoch 840, loss function 1.0442882776260376\n",
      "epoch 841, loss function 1.096863031387329\n",
      "epoch 842, loss function 1.0167337656021118\n",
      "epoch 843, loss function 1.1168838739395142\n",
      "epoch 844, loss function 1.1398242712020874\n",
      "epoch 845, loss function 1.0688484907150269\n",
      "epoch 846, loss function 1.0552178621292114\n",
      "epoch 847, loss function 1.0171337127685547\n",
      "epoch 848, loss function 1.0111316442489624\n",
      "epoch 849, loss function 1.0506008863449097\n",
      "epoch 850, loss function 0.9945350289344788\n",
      "epoch 851, loss function 1.0329217910766602\n",
      "epoch 852, loss function 1.0277578830718994\n",
      "epoch 853, loss function 1.0787158012390137\n",
      "epoch 854, loss function 1.125982642173767\n",
      "epoch 855, loss function 1.044384479522705\n",
      "epoch 856, loss function 1.1045222282409668\n",
      "epoch 857, loss function 1.1868258714675903\n",
      "epoch 858, loss function 1.0003024339675903\n",
      "epoch 859, loss function 0.9627081751823425\n",
      "epoch 860, loss function 1.1140426397323608\n",
      "epoch 861, loss function 0.9979394674301147\n",
      "epoch 862, loss function 1.0572925806045532\n",
      "epoch 863, loss function 1.0917826890945435\n",
      "epoch 864, loss function 0.9241883754730225\n",
      "epoch 865, loss function 1.0543628931045532\n",
      "epoch 866, loss function 1.060569405555725\n",
      "epoch 867, loss function 1.0854840278625488\n",
      "epoch 868, loss function 1.0053799152374268\n",
      "epoch 869, loss function 1.0512855052947998\n",
      "epoch 870, loss function 1.0686014890670776\n",
      "epoch 871, loss function 1.0541502237319946\n",
      "epoch 872, loss function 1.0173683166503906\n",
      "epoch 873, loss function 1.1177222728729248\n",
      "epoch 874, loss function 1.099745512008667\n",
      "epoch 875, loss function 1.0123628377914429\n",
      "epoch 876, loss function 1.0882670879364014\n",
      "epoch 877, loss function 1.0254782438278198\n",
      "epoch 878, loss function 1.0927537679672241\n",
      "epoch 879, loss function 1.0826704502105713\n",
      "epoch 880, loss function 1.0675396919250488\n",
      "epoch 881, loss function 1.0243672132492065\n",
      "epoch 882, loss function 0.9996376633644104\n",
      "epoch 883, loss function 1.076894760131836\n",
      "epoch 884, loss function 1.1405880451202393\n",
      "epoch 885, loss function 1.0875085592269897\n",
      "epoch 886, loss function 1.0519391298294067\n",
      "epoch 887, loss function 1.0706549882888794\n",
      "epoch 888, loss function 1.1241010427474976\n",
      "epoch 889, loss function 1.044710636138916\n",
      "epoch 890, loss function 1.0287621021270752\n",
      "epoch 891, loss function 1.047123908996582\n",
      "epoch 892, loss function 1.049687147140503\n",
      "epoch 893, loss function 1.100682020187378\n",
      "epoch 894, loss function 1.1222147941589355\n",
      "epoch 895, loss function 1.1670304536819458\n",
      "epoch 896, loss function 1.151533842086792\n",
      "epoch 897, loss function 1.0914114713668823\n",
      "epoch 898, loss function 1.1241095066070557\n",
      "epoch 899, loss function 1.0362972021102905\n",
      "epoch 900, loss function 1.0610486268997192\n",
      "epoch 901, loss function 0.9701139330863953\n",
      "epoch 902, loss function 0.9451647400856018\n",
      "epoch 903, loss function 1.1081483364105225\n",
      "epoch 904, loss function 1.1734410524368286\n",
      "epoch 905, loss function 1.1131619215011597\n",
      "epoch 906, loss function 0.9770298004150391\n",
      "epoch 907, loss function 1.1628353595733643\n",
      "epoch 908, loss function 1.1458402872085571\n",
      "epoch 909, loss function 1.2111402750015259\n",
      "epoch 910, loss function 1.1004111766815186\n",
      "epoch 911, loss function 1.0430552959442139\n",
      "epoch 912, loss function 1.0775703191757202\n",
      "epoch 913, loss function 1.1271988153457642\n",
      "epoch 914, loss function 1.1683194637298584\n",
      "epoch 915, loss function 1.01279878616333\n",
      "epoch 916, loss function 1.076799750328064\n",
      "epoch 917, loss function 1.0327116250991821\n",
      "epoch 918, loss function 0.9620232582092285\n",
      "epoch 919, loss function 1.179561972618103\n",
      "epoch 920, loss function 1.0667130947113037\n",
      "epoch 921, loss function 1.019230842590332\n",
      "epoch 922, loss function 1.1100521087646484\n",
      "epoch 923, loss function 1.094528317451477\n",
      "epoch 924, loss function 0.9936637282371521\n",
      "epoch 925, loss function 1.1003141403198242\n",
      "epoch 926, loss function 1.0497984886169434\n",
      "epoch 927, loss function 1.0132136344909668\n",
      "epoch 928, loss function 1.094486951828003\n",
      "epoch 929, loss function 1.163130521774292\n",
      "epoch 930, loss function 1.1297277212142944\n",
      "epoch 931, loss function 1.0949510335922241\n",
      "epoch 932, loss function 0.8760027289390564\n",
      "epoch 933, loss function 0.9788857102394104\n",
      "epoch 934, loss function 1.0852082967758179\n",
      "epoch 935, loss function 1.1645921468734741\n",
      "epoch 936, loss function 1.055883765220642\n",
      "epoch 937, loss function 1.0045738220214844\n",
      "epoch 938, loss function 1.0130674839019775\n",
      "epoch 939, loss function 1.11201810836792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 940, loss function 1.0773526430130005\n",
      "epoch 941, loss function 1.1119272708892822\n",
      "epoch 942, loss function 1.0246869325637817\n",
      "epoch 943, loss function 1.1467173099517822\n",
      "epoch 944, loss function 1.017823338508606\n",
      "epoch 945, loss function 0.9500565528869629\n",
      "epoch 946, loss function 1.0967106819152832\n",
      "epoch 947, loss function 1.044886827468872\n",
      "epoch 948, loss function 1.174060344696045\n",
      "epoch 949, loss function 1.081032633781433\n",
      "epoch 950, loss function 1.0706204175949097\n",
      "epoch 951, loss function 0.96892249584198\n",
      "epoch 952, loss function 1.139272689819336\n",
      "epoch 953, loss function 1.0480012893676758\n",
      "epoch 954, loss function 1.0638163089752197\n",
      "epoch 955, loss function 1.0826829671859741\n",
      "epoch 956, loss function 1.0866355895996094\n",
      "epoch 957, loss function 1.108311414718628\n",
      "epoch 958, loss function 1.0649943351745605\n",
      "epoch 959, loss function 1.1015756130218506\n",
      "epoch 960, loss function 1.0824897289276123\n",
      "epoch 961, loss function 1.0854432582855225\n",
      "epoch 962, loss function 1.0928975343704224\n",
      "epoch 963, loss function 0.9575912356376648\n",
      "epoch 964, loss function 1.007274866104126\n",
      "epoch 965, loss function 1.100132703781128\n",
      "epoch 966, loss function 1.038190245628357\n",
      "epoch 967, loss function 1.0081816911697388\n",
      "epoch 968, loss function 1.0361229181289673\n",
      "epoch 969, loss function 1.052834153175354\n",
      "epoch 970, loss function 0.9593378305435181\n",
      "epoch 971, loss function 1.061700463294983\n",
      "epoch 972, loss function 1.0577970743179321\n",
      "epoch 973, loss function 1.047351360321045\n",
      "epoch 974, loss function 1.0456438064575195\n",
      "epoch 975, loss function 0.9866954684257507\n",
      "epoch 976, loss function 1.0622999668121338\n",
      "epoch 977, loss function 1.0348248481750488\n",
      "epoch 978, loss function 1.0696265697479248\n",
      "epoch 979, loss function 1.035719633102417\n",
      "epoch 980, loss function 1.0648454427719116\n",
      "epoch 981, loss function 1.0857350826263428\n",
      "epoch 982, loss function 1.1222186088562012\n",
      "epoch 983, loss function 1.1379002332687378\n",
      "epoch 984, loss function 1.0550098419189453\n",
      "epoch 985, loss function 1.0373603105545044\n",
      "epoch 986, loss function 1.0106511116027832\n",
      "epoch 987, loss function 1.0649882555007935\n",
      "epoch 988, loss function 1.0318458080291748\n",
      "epoch 989, loss function 1.1059247255325317\n",
      "epoch 990, loss function 1.080506443977356\n",
      "epoch 991, loss function 1.1051088571548462\n",
      "epoch 992, loss function 0.980460524559021\n",
      "epoch 993, loss function 0.922233521938324\n",
      "epoch 994, loss function 1.1450791358947754\n",
      "epoch 995, loss function 1.0106041431427002\n",
      "epoch 996, loss function 1.0376734733581543\n",
      "epoch 997, loss function 1.160426139831543\n",
      "epoch 998, loss function 0.9401368498802185\n",
      "epoch 999, loss function 1.0361419916152954\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "data = Data(x=dataset.x, y=dataset.y)\n",
    "data = data.to(device)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        torch.manual_seed(12345)\n",
    "        self.normalizer = nn.LayerNorm(data.x.shape[1])\n",
    "        self.linear1 = torch.nn.Linear(data.x.shape[1], 100)\n",
    "        self.linear2 = torch.nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.normalizer(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the MLP\n",
    "mlp = MLP().to(device)\n",
    "\n",
    "\n",
    "mlp.train()\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4, weight_decay=5e-4)\n",
    "  \n",
    "# Run the training loop\n",
    "for epoch in range(0, 1000):\n",
    "    # Get and prepare inputs\n",
    "    inputs, targets = data.x[idx[:num_train]], data.y[train_mask].squeeze()\n",
    "      \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "      \n",
    "    # Perform forward pass\n",
    "    outputs = mlp(inputs).squeeze()\n",
    "      \n",
    "    # Compute loss\n",
    "    loss = loss_function(outputs.squeeze(), targets)\n",
    "      \n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "      \n",
    "    # Perform optimization\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    print('epoch {}, loss function {}'.format(epoch, loss.item()))\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:-0.4178051938050149\n",
      "mse:0.7470750808018093\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mlp.eval()\n",
    "    pred = mlp(data.x[idx[num_train:]])\n",
    "    y_true = data.y[test_mask].squeeze().tolist()\n",
    "    y_pred = pred.squeeze().tolist()\n",
    "    print('r2:%s' % r2_score(y_true, y_pred))\n",
    "    print('mse:%s' % mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the rest of the baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = data.x[idx[:num_train]].tolist(), data.y[train_mask].squeeze().tolist()\n",
    "scaler = MinMaxScaler()\n",
    "x_test, y_test = data.x[idx[num_train:]].tolist(), data.y[test_mask].squeeze().tolist()\n",
    "scaler.fit(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:-8.081695653207058\n",
      "mse:4.785360177535206\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(scaler.transform(x_train), y_train)\n",
    "print('r2:%s' % reg.score(scaler.transform(x_test), y_test))\n",
    "print('mse:%s' % mean_squared_error(y_true, reg.predict(scaler.transform(x_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:-0.2427040152124984\n",
      "mse:0.65481012951155\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(max_depth=5, random_state=42)\n",
    "reg.fit(scaler.fit_transform(x_train), y_train)\n",
    "print('r2:%s' % reg.score(scaler.transform(x_test), y_test))\n",
    "print('mse:%s' % mean_squared_error(y_true, reg.predict(scaler.transform(x_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:-0.9752265271142317\n",
      "mse:1.0407935616214714\n"
     ]
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "reg.fit(scaler.fit_transform(x_train), y_train)\n",
    "print('r2:%s' % reg.score(scaler.transform(x_test), y_test))\n",
    "print('mse:%s' % mean_squared_error(y_true, reg.predict(scaler.transform(x_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
